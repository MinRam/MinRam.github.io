{"posts":[{"title":"胡言乱语 —— 核心竞争力","text":"本系列，是自己职业发展经验的笔记。希望读者在看完全文后，也能留下你们的经验或者问题。如果能从这里学到点东西，记得请我喝杯☕☕☕~ —— MinRam","link":"/hu-yan-luan-yu/careerdeployment-01-corecompetency/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/hexo/hello-hexo/"},{"title":"Git 分支策略模型","text":"本系列，是自己学习Linux过程中的笔记。希望读者在看完全文后，也能留下你们的经验或者问题。如果能从这里学到点东西，记得请我喝杯☕☕☕~ —— MinRam 在整理自己项目Polaris Technology Radar的分支策略时，采照了当前商用级分支策略，写了些个人对这种分支模式的理解。如果产品是处于持续交付策略，那么可能更适合GitHub flow的策略，不要试图将Git硬塞入你的产品团队同时分支策略不是唯一固定的，我们需要适配产品需求。对于IT，没有万能钥匙存在。 一、前言 Overview本文章仅描述我自己项目中的分支策略和发布管理。当我们选择分支策略时候，应考虑产品的迭代模式，团队的开发规模和开发方式等方面。 以Polaris Technology Radar为例，该项目有如下几个信息： 项目开发团队人数 2~10人 项目代码规模小，满足单人开发条件 项目发布流程涉及多种环境部署 项目可能支持多个发布版本并存（正式版本/定制版本） 团队开发模式为功能特性独立 … 二、为什么选择GitGit作为一款版本控制系统VCS-Version Control System, 是开源项目不二的选择。让来自不同开发者的分支能够简单的对比/合并。 同样作为VCS的SVN- Apache Subversion, 没法连接数据库就没法工作，同时SVN只能满足在少量开发者的场景下进行版本管控。 三、主分支 Main Branches受开发模式影响，整个项目存在两个永存的分支： release &amp; develop. 3.1 Release Branches我们认为release为主分支，其中的代码始终满足发布状态，包含对下一版本要交付的功能特性代码。 该分支也是自动化构建的目标分支，只有该分支的代码，才会被发布到生产环境上。 3.2 Develop Branches如名所示，develop分支是处于开发测试中的代码。 只有当代码变动趋于稳定后并准备发布的时候，所有代码变动会以某种方式合并到release分支中，并且标记版本号。 这一合并动作会在后面进一步详解。 所以，每次develop的代码变更，合并到master时，这就是一个针对生产环境的代码版本。 我们往往在这个合入动作（Pull Request)发生时，触发自动构建机制（DevOps, 如Git hook脚本）来构建我们的产品，并自动部署到生产环境上。 四、支持性分支 Supporting Branches除了主分支(release &amp; develop)的存在，依照我们开发模型，在整个分治策略中还有各种支持性分支，来协助团队成员进行并行开发，简化功能定位，以及为生产环境做准备。 有些分支也会协助开发者，快速修复实时生产环境上的问题。 与主分支的永久生命周期不一样，支持性分支的生命寿命是有限的，最终都会被删除。 对于这些支持性分支，大致包含以下几类： 功能性分支 发布性分支 热补丁分支 这些分支都有明确的特定目标，并且遵循一定的原则。如只能从哪些分支上分叉出来，只能合入哪些分支。 从Git的角度上看，这些分支没有任何区别，同样只是普通的代码分支，只是因为其目的特殊，所以有着特殊的含义。 4.1 特性分支 Feature Branches 根源分支： develop 目标分支： develop 分支命名规则： 一般以feature-*为命名规则，同时不包含release, develop和hotfix字样 功能分支，用于为即将发布的版本开发新功能。在开发该功能特性时，我们无法预估该功能最终会在哪个版本进行发布。但对于功能分支来说，只要功能还在开发，分支就一直存在。 对于该分支，它生命周期的终点，要么功能开发完成，合并入develop,准备发布。 要么因项目安排，功能被取消，最后直接删除分支。 功能分支，通常仅存在开发人员本地Git存储库中，不会存在远端代码仓库(origin）。 创建功能分支： 从develop中创建。 12$ git checkout -b feature/hello-world developSwitched to new branch 'feature/hello-world' 完成功能开发，合并代码变动: 在实际代码管理中，往往需要提交Pull Request，经过代码审查Review, 代码构建Build/Test来保证代码准确性。这里仅展示本地合并指令。 12345678$ git checkout developSwitched to branch 'develop'$ git merge --no-ff feature/hello-worldUpdating ea1b82a..05a893(Summary of changes)$ git branch -d feature/hello-worldDeleted branch feature/hello-world$ git push origin develop --no-ff 该参数, 用来避免丢失特性开发分支的整个提交链信息，同时创建新的代码提交信息。具体详见Git fast forward merge内容。 以下为两者简单对比： Pull Request中也有同样的选项。 4.2 发布分支 Release-* Branches 根源分支: develop 目标分支：develop/release 分支命名规则: release-* release-* branches是为下一版本的发布做准备。他是正式发布前的预先检查环节。不同于develop分支对应的测试环境，release-对应的环境，更符合生产环境的标准，且在release-分支上只允许补丁相关的变动。 创建发布分支 release-*是从develop创建出来的。假设当前的生产版本为1.2, 而develop已经完成新版本1.3所有的功能特性，我们就可以从develop中分支出release-1.3。 1234567$ git checkout release-1.3 developSwitched to branch 'release-1.3'$ ./bump-version.sh 1.3Files modified successfully, version bumped to 1.3.$ git commit -a -m &quot;Bumped version to 1.3&quot;[release-1.3 74d9424] Bumped version number to 1.31 files changed, 1 insertions(+), 1 deletions(-) 接下来就是修改release-1.3上的版本信息，比如配置上的版本号。这里用bump-version.sh来自动更新这类信息。 release-*分支会一直存活，直到合并到release发布, 或者被删除.在此分支上，不得合入较大的功能变动。 完成发布分支 当release-1.3已经满足发布条件后，我们需要将该分支合入release中。同时我们需要在这次合入中打入特定标签，来保证我们能在后续众多的提交中，找到指定版本的发布提交点。 首先，需要更新release的标签到新的版本号。 123456$ git checkout releaseSwitched to branch 'release'$ git merge -no-ff release-1.3Merge made of recursive.(Summary of changes)$ git tag -a 1.3 另外，为了保留release-*的变动，我们还需要将release-*合并到develop，以保证所有的变动能在下一个版本中被包含。 12345$ git checkout developSwitched branch to 'develop'$ git merge -no-ff release-1.3Merge made of recursive.(Summary of changes) 最后，就是永久性的删除该分支 12$ git branch -d release-1.3Delete branch release-1.3 (was fsae5d6) 4.2 热补丁分支 Hotfix Branches 根源分支: release 目标分支：develop/release 分支命名规则: hotfix-* 热补丁分支同发布分支非常相似，同样为新生产版本做变动。不同的是，热补丁是计划外的。 在生产版本中总会出现一些关键Bug，需要立即采取措施来修复。我们就从生产版本的主分支分支出补丁分支来修复这类问题。 采取这样的策略，可以保证develop分支上的开发团队可以继续专注于下一版本的特性开发。而由单独的团队来快速修复这一紧急问题。 补丁分支创建热补丁分支是由release分支出来的。例如生产环境出现了一个严重的Bug，但当前的develop的功能并不稳定，这是我们就会从release分支出hotfix branches，然后在这条分支中开始修复致命问题。 1234567$ git check -b hotfix-1.0.1 releaseSwitched to a new branch &quot;hotfix-1.0.0&quot;$ ./bump-version.sh 1.0.1Files modified successfully, version bumped to 1.0.1$ git commit -a -m &quot;Bumped version number to 1.0.1&quot;[hotfix-1.0.1 41e61bb] Bumped version number to 1.2.11 files changed, 1 insertions(+), 1 deletions(-) 在创建出补丁分支后，不要忘了更新版本号，此处用bump-version.sh代表这一动作。来描述该分支版本变化（1.0.0 --> 1.0.1)。 接下来就是在这个分支上，修复所需要的Bug。 补丁分支完成 补丁分支的创建，需要合并到主分支release。同时也需要合并入develop分支，以确保该补丁能在下一个开发版本被修复。 此处为release，而不是release-*。 首先，需要更新release的标签到新的版本号。 123456$ git checkout releaseSwitched to branch 'release'$ git merge -no-ff hotfix-1.0.1Merge made of recursive.(Summary of changes)$ git tag -a 1.2.1 下一步，就是将补丁合入develop。 12345$ git checkout developSwitched to branch 'develop'$ git merge -no-ff hotfix-1.0.1Merge made of recursive.(Summary of changes) 如果当前存在release-*分支，我们可以直接合入release-*，而不用合并入develop。 最后就是删除这一临时分支，及时清理无用分支，来保证整个仓库的简洁。 12$ git branch -d hotfix-1.0.1Delete branch hotfix-1.0.1 (was abbe5d6) 五、总结 Summary整个分支策略模型并没有什么新颖的技能点，但从分支管理角度，它反映整个产品的开发模型。为团队建立一个对开发和发布流程的共识。","link":"/git/gitbrancing-01-multibranches/"},{"title":"程序员面试攻略 —— 简历","text":"一、前言 Overview在我的职业生涯中，至今为止应聘过3家公司。其中对于我来说，最难的不是现在的Offer，而是本科毕业出来时候，第一次找到的工作。 在那时候，我经常吐槽学校的培养计划，在大学四年中，仅存的软技能课只有职业生涯规划，而里面的知识又和实际职场严重脱轨。这么重要的知识，却没法在大学时期能够很好的重视和培养，最后在毕业季进行磕磕碰碰地就业，也浪费了自己应届生的优势。 在我进入工作之后，渐渐明白： 程序员，永远不只是代码。这个岗位，他首先是一个职业，包含了应聘，沟通，领导等能力；接着是一名IT技术员工，拥有擅长领域的IT技术；其次是一名工程师，赋予工程学技能框架。最终才实现技能变现。 我非常感谢陈皓哥给予的宝贵经验，让自己能够跟随着他的脚步，在毕业前能提交出一份堪堪及格的答卷。也在之后的职业道路上，一直能有一盏明灯引领着自己，去进步，去发展。 二、简历的基本要素 Basic简历，基本上来说，应该简要明了，筛选能有利于自己应聘岗位的信息，不能单纯罗列，要突出自己的技能和长处，给予招聘方想要的信息。 通常来说简历，包括以下几个部分： 2.1 个人信息 自我介绍 这个自我简介是用最简单的话来说明自己的情况，不超过 200 字，自述不超过5分钟。 比如：10+ 年的软件开发经验（说明你的主业），4+ 年的团队 leader 经验（说明你的领导力），擅长高可用高性能的分布式架构（说明你的专业和专攻），多年互联网和金融行业背景（说明你的行业背景），任职于 XXX 公司的 XX 职位（说明你的职业），负责 XXX 平台或系统（说明你的业务场景）··· 基本信息 包括姓名，年龄，性别，联系方式（电话 + 邮箱)， 个人证件照 其中姓名在面对国际公司（主要指大厂）可以带上英文名；联系电话可以加上国区号（如+86）；邮箱建议选择更具职场性质的邮箱（如Gmail,hotmail)，少用QQ邮箱，国企类型的可以选择网易邮箱等；个人证件照意义不大，可以不加，毕竟不看脸； 个人网站 主要指个人主页、博客、GitHub 或是 Stack Overflow等平台，是很好的作品展示方式 如果有自己的独立域名，很建议附在你的简历，这就是你动手能力的加分项。同时对于前端领域，自己设计的博客，就是一个很好的招牌和审美品味的展示。但应注意自己博客中的内容，反应自己的思考深度，对技术原理性的刨根问底，对技术的偏执和看法。 个人技能 罗列几条个人技能，快速阐明已掌握的技术和领域。不应太多，点睛即可。 如果是从招聘简章上面试的，上面的要求，就是你该选择突出什么技能的纲要。 – 技术领域 —— 前端，算法，AI，分布式，系统底层，DBA等 – 业务领域 —— 行业领域（金融，通信，电商，政务等）&amp; 业务领域（支付，CRM，物流等） – 技术领域 —— 表明自己专精的编程语言，编程框架，常用软件/工具，设计或架构 – 经验和软技能 —— 主要指领导力，执行力，项目管理能力，设计能力。 工作经历和教育经历 工作经历和教育经历都应服务于证实和描述个人技能的高度 根据项目的含金量和同竞聘岗位的关联性，从大到小列出自己的工作经历和项目，应突出项目的含金量（难度，规模，挑战，自己的职责和输出，以及他人的认可）， 个人建议参照STAR法则，梳理自己的项目。 三、简历模板 Template简历，应突出简介明了。几点琐碎要求： 简历的内容应简短精确，控制在两页内； 简历格式在提交时，应为PDF格式，保证格式不会混乱； 面对国际企业或有英文工作环境的企业，应附带英文版简历，处理好里面的描述和基本语法（这将体现你的英语功底）； 简历的模板，可以参照Office上关于简历的模板，主要以简约风格为佳； 简历中的罗列多点的地方应控制2-3个，不应过多； 自我评价模块，内容虚浮，个人并不建议添加。对于大部分公司，并不在意你的自我评价，他们更相信自己看到的和考验出来的； 四、知识储备 Knowledge 以上提到的内容，应严格按照自己的情况如实填写。 有人提过面试会问什么内容？其实简历就是面试官问你的一亩三分地。你写什么，面试官就会问你什么。对于大厂和行业前端的公司，就不要打肿脸充胖子，是什么就是什么。面试官在面试时会不断试探我们知识领域的广度和深度。 你写上了 Java，那么 Java 的基本语法都要了解，并发编程、NIO、JVM 等，你多少要有点儿了解，Spring、Netty 这些框架也要了解。 你写上了 Go，那么至少得把官网上的 Effective Go 给看了。 你写上了 Redis，那么除了 Redis 的数据结构，Redis 的性能优化、高可用配置、分布式锁什么的，你多少也要把官网上的那几篇文章读一读。 你写上了面向对象，那么怎么着也得把《设计模式》中的 23 个模式了解一下。 你写上了分布式架构，那么 CAP 理论、微服务架构、弹力设计、Spring Cloud、Cloud Native 这些架构就要做到心里有数。 你写上网络编程，那么 TCP/IP 的三次握手，四次挥手，两端的状态变化你得知道吧，Socket 编程的那几个系统调用，还有 select、poll、epoll 这些异步 IO 多路复用的东西，你得知道。 对于关键技术，你至少要有八成功力，以及一定的深度原理学习。 对于算法知识，刷题就完事，👉点我👈 对于系统设计，一般只有在社招面试才会提到，可以参考我《简单系统设计》 五、经典问题 (拓展) Question面试中总有几个经典问题，往往需要提前准备： 说一个你做过的最自豪的项目，或是最近做过的一个项目。 了解候选者的兴趣点，和高质量项目。 说一个你解决过的最难的技术问题，或是最有技术含量的问题。以及如何解决的 了解候选者对难题的处理能力。 说一个你最痛苦的项目，或最艰难的项目。 了解候选者的抗压能力。 说一个犯过的最大的技术错误，或是引发的技术故障。 了解候选者对错误的态度，以及是否能够自我改正或优化。 这些问题都会伴随着对各种细节的不停追问，因为这样的问题太容易造假了。所以，面试官会不停地追问细节，就像审问一样。因为一个谎言需要用更多的谎言来掩盖，如果没有经过高强度和专业的训练的话，最好不要撒谎。 对此，如果你想有一个比较好的面试回答效果，这不是你能临时准备出来的，工夫都是花在平时的。笔者的方式就是在工作中写文档 ，在工作之余写博客。能讲得清，讲得好，就能在面试中有较好的语言组织能力和工作总结能力。 六、小结 Summerize简历总的来说，就是突出面试官想要的，简历内容有限，不应长篇大论。 参考 [1] The Google Résumé: How to Prepare for a Career and Land a Job at Apple, Microsoft, Google, or any Top Tech Company","link":"/cheng-xu-yuan-mian-shi-gong-lue/interviewresume/"},{"title":"程序员面试攻略 —— 薪资构成","text":"这篇文章是自己在面试准备中，参照他人经验以及自身总结经历的随笔。希望读者在看完全文后，也能留下你们的经验。我万分荣幸能收到你们的消息。如果能从这里学到点东西，记得请我喝杯☕☕☕~ —— MinRam 前言开篇时候膜一下《中国人民共和国劳动法》。 吐槽下官网互联网建设不足，急需IT人才~ 一、薪水构成科技公司的小伙伴们会用 TC (Total Compensation)，来表示实际收入总包。总包的计算方法各公司稍有不同，但无外乎包括以下几个部分： 基本工资 Base (五险一金、个人收入所得税) 年终奖 Bonus 股票 Equity (RSU/Option) 初始股票 Initial grant 新发股票 Refresh 而再详细点 二、看得到的工资2.1 基础工资 Base Salary这是在入职合同上填写的固定收入，具体是根据入职时候的市场价、面试表现、职位等级决定的。入职后将随公司策略有一定的涨幅。 可以理解为，这是公司每个月给我们的月薪。在扣除五险一金，工资税后，剩下的会转账到个人工资卡上，也就是你实际到手的金额。 工资税的计算， 可以查看 中华人民共和国个人所得税法, 可以通过个人所得税APP查看， 从当地的本地宝公众号查询。回复“个税”，可以直接进入个人所得税入口。 五险一金，查看下文。 2.2 年终奖 Bonus 年终奖，是老板给予员工一年来的工作业绩奖励，一般位于年末到年初时候发放。 年终奖主要用来奖励员工一年的业绩表现， 以及摁住员工跳槽的念头。所以我们可以从一年的年终奖看出公司对你的期待。往往年终奖发完的这一阶段，是你进行离职或者跳槽的最佳时间。 年终奖上不封顶，一般为月薪的2个月。 年终奖也是同样需要缴纳个人所得税的。可以查看 《国家税务总局关于调整个人取得全年一次性奖金等计算征收个人所得税方法问题的通知》。 2.3 股票 Restricted Stock Units股票收入主要包含两部分： 初始合同一次性承诺给予股票，分四年（或五年）按月/季度/年发放 各公司政策稍有不同，有些公司在员工入职一年后才开始按季度发（业内叫 one-year cliff），而有些公司入职第一个月就开始发 不是所有公司都等额发放，比如亚麻头两年 5% 和 15%，后面两年各 40%，Snap 也有类似规定。微软，则是等额发放。 每年新发股票 Refresh 每过一年，公司会根据员工表现，新发一定股票，同样也是分四年发完 新入职第一年，不是所有公司都给 refresh，各家公司 refresh 规定都不太一样，会随着市场情况调整，具体情况具体讨论 据说，Uber 把 refresh 当成 bonus 的一部分，分 cash bonus 和 stock bonus 另外在司期间，对于上市公司，可以行使公司股票的购买权（以某个特定价格购买股票的权力） 个人觉得股票避税的两种方式： 等你老了没有这么高工资了再卖，这样capital gain tax braket 比较低（因为交易税和收入税挂钩 如果你有多支股票的话，找机会卖一个亏损的，claim capital gain loss， 然后再卖这个赚钱的，这样两两相抵。 2.4 五险一金 five-insurance payment 再膜一下 《中华人民共和国社会保险法》 五险一金是指用人单位给予劳动者的集中保障性待遇的合称，包括【五险】（养老保险、医疗保险、失业保险、工伤保险、生育保险）和【一金】（住房公积金）。 缴纳基数是社保计算的基数，决定了五险一金的缴纳金额。新入职员工是以起薪当月月收入作为缴纳基数，入职一年以上的员工以上一年月平均收入作为缴纳基数。 注意，有部分公司的社保基数并不会随着你的月薪资增涨而增涨（一个职业坑） 养老保险 (企业 + 个人共同缴纳) 是国家根据法律、法规的规定，强制建立和实施的一种社会保险制度。 在达到法定退休年龄，且累积缴纳养老保险费满15年。 由社保机构每月给你发放的养老金。取决于你交社保的年限，每月缴纳金额，户籍地，职称等决定。 医疗保险（企业 + 个人共同缴纳） 是补偿我们因为疾病造成的经济损失（医药费, 住院费等）建立的社会保险制度。主要是减轻我们的医疗费用负担，每月从我们月薪资扣除保险费用，从而可以报销部分或全部医疗费用。 医保卡， 分成统筹账号和个人账号，具体可参考当地标准。 失业保险（企业 + 个人共同缴纳） 是在我们因失业没有经济来源时候，能给我们提供基础生活保障的一种社会保险制度。 被公司辞的，并且原公司有给你按规定缴纳失业保险。（如果是被辞，按劳动法规定，还需要支付你 N+1 ~ 2N+1的工资费用） 可按月领取失业保险金（满足基本生活费用） 工伤保险（企业缴纳） 在工作或特殊情况下，因意外伤害或者患职业病导致的暂时或永久丧失劳动力和死亡时，劳动者或者遗嘱从国家和社会获得物质帮助的一种社会保障制度 简单来说，因工受伤拿补助。对于程序员，尤其注意自己在“加班期间”如果受伤，需要指明工作期间。 这是企业给员工缴纳的健康保障 生育保险（企业缴纳） 是国家通过立法，在怀孕和分娩的妇女劳动者暂时中断劳动时，由国家和社会提供医疗服务、生育津贴和产假的一种社会保险制度。 一是生育津贴（社保机构发放产假/陪产假期间的工资），二是生育医疗待遇（报销医疗费用） 休产假期间，如果有生育津贴，公司是可以不需要再发放工资（但如果生育津贴如果不足，公司需要补全到月工资水平）。 住房公积金 是国家强制用人单位和雇员按照相同的比例交的一种长期住房储蓄金，专项用于个人支付住房方面的费用。 具体用途就是， 申请贷款买房（利率低），付房租费用，支付房屋装修费，甚至治疗重大疾病。如果实在没有用处，最后满足条件可以全额现金提取。 补充个异地跳槽后，本地公积金可以进行封存，在你新入职一个月后可申请异地转移接续手续。三、看不到的工资 除了以上提到几点，刚入职是还会有一笔现金签字费，入职后一定时间内支付，主要由 negotiation（有无 competing offer、公司多么想招你）决定。 另外，还有各大科技公司著名的好福利，比如健康保险、免费的一日三餐、健身房、游泳池，博物馆免费门票/打折票，车险、房屋保险、租车、买车、滑雪等一系列的 corporate rate，免费/打折的衣服干洗、理发、体检，commuter benefit 报销上下班公共交通，等等。 例如, 微软，提供餐补，健身费用和培训费用报销，医疗保险公司全额报销，足额公积金等。如有兴趣，拿简历砸我吧！ >- 已阅留爪，分享自己公司福利制度 (ฅ´ω`ฅ) -","link":"/cheng-xu-yuan-mian-shi-gong-lue/interviewincoming/"},{"title":"Linux操作系统 —— 开篇（一）","text":"本系列，是自己学习Linux过程中的笔记。希望读者在看完全文后，也能留下你们的经验或者问题。如果能从这里学到点东西，记得请我喝杯☕☕☕~ —— MinRam 一、前言 无论是从我个人职业发展，还是公司的招聘机会来看，扎实的基础知识都显得尤为重要。 前系列讲述了面试中需要的系统设计知识。这次回归基础知识，选择从最基本的Linux系统开始。 最近一次系统性的学习系统是大学时候的《计算机组成原理》，学到的内容都是讲理论，讲原理，甚至无法通实际项目中的linux相结合。 例如在考虑系统内核参数或内存分配时，完全无法关联起来，因为我自己就不了解系统底层是如何调配资源的，自然也无法给出合理的调参建议。虽然后面有碎片性主动或被动地学习一些，但由于没有系统学习，我在这块是缺少知识地图，来完成知识联动。 二、为什么选择Linux从W3Techs可以得到两份调查数据分别是：《软件系统中操作系统使用情况》 和 《软件系统中Unix中各系统使用情况》。 从调查数据得出的结论是在现在的软件系统中Unix是后端操作系统的主流，其中Linux更为常见。 随着云计算的发展，很多商业级产品都在进行云化，大部分的计算都是由后端来完成的。 随着移动互联网的发展，其终端（手机&amp;穿戴设备）中以安卓为主，而安卓其实是基于Linux内核运行。 主流技术：虚拟化，容器都是基于Linux核心技术。所以不管是应用开发，移动平台还是穿戴嵌入式开发，Linux一直都是必须啃下的硬骨头。 三、开源Linux1. Linux的内核代码 Linux是一个开源OS，不像Windows。 这意味着，只要足够耐心，你可以从代码中，把Linux完完整整犁一遍。看Linux是如何进行内核调度，内存分配等。理论知识可能会理解偏差，代码却不会说谎。 在实际开发中，Linux代码上有着各种各样的经典案例，从数据结构到设计模式再到并发。实际上，这些代码案例都是经过了开发者和商用产品的实践，经得起考验。 比如在应用开发中，经常需要使用各种数据结构和算法库。在内核代码中，为了保证内存消耗，检索耗时或更新耗时限制在合理范围内，Linux常常使用一些自定义的结构，这在我们开发中很有参考价值。 2. Linux的技术生态 Linux作为各大商用级产品的首选的原因之一，就是有着庞大的产品工具生态。 我们已知的各大组件都可以看到Linux的地位： 数据库上的Mysql、Oracle、Mongodb, 消息队列 RabbitMQ、Kafka, 虚拟化 KVM、Openstack、Openswitch，容器 Kubernetes、Docker。这些技术软件在开发的时候都会优先考虑Linux的场景，整个生命周期（安装，使用，升级，运维）都会先完成Linux生态栈。 在Linux中，我们可以看到这些商用级工具的开发者的设计理念和思想。 3. Linux的社区生态 Linux的背后有各种业界大佬和巨头公司撑腰。 由于Linux的各种优点，让全世界更多的开发者甘愿参与进来完善，其中更有IBM、ARM等一系列巨头公司参与，形成一种Linux为世界各地开发者提供方便，开发者通过参与提高能力，IBM等公司通过开发驱动将自己硬件设备应用在Linux，从而促进Linux继续壮大的互利形态。到如今，近乎全世界的OS开发者均或多或者投入到Linux开发和bug修复中，绝大部分公司均基于Linux开发自己的商业OS。 这基本就是Linux作为一个开源软件的生态，它是所有商用发布OS的核心，是所有主流厂商的承认的操作系统，厂商如果希望Linux可以运行自己硬件，那么必须将硬件驱动加入Linux并维护，从而将主流厂商与Linux绑定更加紧密。 可以说，如果我们在Linux上碰到问题，肯定不是只有我们碰到。 四、Linux的发展Linux是一个大家族，看图","link":"/linux-cao-zuo-xi-tong/operationsystem-01-openning/"},{"title":"程序员面试攻略 —— 薪资谈判","text":"这篇文章是自己在面试准备中，参照他人经验以及自身总结经历的随笔。希望读者在看完全文后，也能留下你们的经验。我万分荣幸能收到你们的消息。如果能从这里学到点东西，记得请我喝杯☕☕☕~ —— MinRam 一、谈工资需要谈工资，就是要钱，赤裸裸要钱，要完钱后还是要钱。整个过程需要承担一定的风险，存在谈崩的可能。 如果觉得工资是由能力决定的，公司会根据自己能力很公平的裁定的人，大可跳过这个回答。 比如我，把自己比喻成商品，信奉市场供需关系。不是公司单方面决定我的工资，定期准备面试，保证自己的市场竞争能力。 二、谈工资的人群如果你是实习生&amp;应届生，那谈工资的空间并不大，那俩都是差不多的背景，拿IT类职位，一年收入差距大概一两万。如果是经验丰富的，能通过谈薪提高几万年薪。 不过我自己还是建议尽早开始练习谈薪，毕竟这样的机会不多，为未来的自己提前练习谈薪资。薪资是一步步往上提高的，每一步都要争取最大利益化。（谈薪过程巨刺激） 三、公司方面的面试成本有个指标叫做CPH (cost per hire)，人均招聘成本。招聘一个合格工程师，需要花费多个款项，包括简历来源、招聘工具、中介代理费、候选人的差旅和住宿、招聘活动开支。 除此之外，还包括招聘团队的薪资，鼓励奖金，甚至是技术面开发人员带薪面试。（打断一个有面试能力的开发人员去组织面试，需要花费更多的时间让他回归到原来的工作上) 加上并不是每次应聘者都能符合要求，拿到offer。或者是拿到offer的应聘者，最后也有一定的概率拒绝offer。当你拿到offer时，公司已经在你身上花费了很多时间和钱。 另外负责跟你交接的HR，可以了解他们薪资体系，绩效奖金（入职率）占据他们大部分的薪水。他们具有很强的动力，撮合你和公司的缘分。（听说有的公司会选择第二个HR来谈薪，避免这种事情。） 综上，如果你通过了面试，拿到offer，公司内部所有人都希望你能接受，而不是拒签。 四、公司初步定薪套路每个职位，都有对应的级别，以及相应级别的薪资范围，同样的级别也会有高薪低薪之分。另外同样的职位，绝大部分不会给上限工资，这涉及到公司的工资预算。 HR给的offer数字，会考虑： 能低价就低价（大部分人就这样被牵着鼻子走） 会给后面的提薪留余地（如果你有讨价的话） 太低了，可能会直接被拒。 HR往往会依照明确的参考标准（比如不断询问你当前的薪资水平），再加上一定的涨幅出价。 注意，HR并不会根据你的能力出价的。能力是个不可以客观量化的东西。仅仅通过面试是很难考察出一个人的真正能力（面试表现好≠工作能力好）。 另外，你的老雇主出10万就能招到你，我司为何要出20万甚至30万？增加20%，一年给12万就很好了。还有，你为什么只值10万？是不是能力其实也就那么回事啊。尤其是好多年没跳槽的人，是不是没有能力拿高薪？这些想法未必正确，但是从公司的角度来看，有这些疑问，不算过分。 再给出几个不同角度的参考因素： 不利的一面： 应聘旺季，如春招秋招，公司有较多的候补人，此时供大于需，公司大概率不在乎你。 应届毕业生，应届毕业生的工资，一般有经验的HR都能猜到，回到明确参考标准那点。 老钉子户，由于长时间未挪窝，基本丧失市场竞争力，HR就会按市场平均水平直接给。（当然，对于资深高级人员，往往通过猎头来寻求谈判。） 进城户，之前的生活消费水平低，迁移到较好的城市，这种对于HR会给较低薪资，因为好打发。 有利的一面： 缺人的岗位&amp;技能，意味着你是个香饽饽，卖方市场，会有多家公司抬价。 海王，待过多家公司（非负面记录），工作多年，经验老道，HR猜不到你工资。 大公司背景，会给HR足够的俯视压力。 公司周边基建因素，诸如当前国内存在大公司往郊区迁移，周边配套服务往往不足。 还有其他的因素，不一一例举。以上也能作为就业参考因素。 五、谈判前的准备工作 合理安排面试时间，能保障手上有多份Offer。多份Offer在手，方便比较竞价。同时就算谈崩了，也有其他offer，能走选择的余地。如何合理安排时间，就需要考虑到公司的招聘速度。这个参考对应面经，或直接询问hr即可。 说下公司竞价的原因，之前提过，一场面试并不能衡量一个人的各方面素质，能满足职位要求。每家公司都出现过，招聘后不能给出有效产能的员工，最后只能开除或者内部调岗。 然而，如果你拿到了多家公司的Offer，得到多家公司的认可，这就是一个很强的信号。经过了多轮面试的考研，大家都认可。公司非常愿意高价招手握一把Offer、大家都说好的求职者。 不透露当前工资水平。对这个就是，不说，不谈，不填。 大部分公司是不能看到前东家薪资的。（进去背调后才会要求工资流水）没必要说，也没必要虚报，不说就行。工资是根据当前的背景和经验决定的，选择了寻找新公司，就说明当前薪资是不满足自己的价值的。那新公司又有啥理由，以此为借口继续打压？ 六、谈判Tips在公司已经给出具体工资数字情况下，如何继续讨价还价 双方保持兴趣是前提 如果你没兴趣加入这家公司，甚至对公司的前景不看好。那就算你再牛叉，对公司来说，招聘你并不会带来任何收益。公司会果断取消Offer。你需要对公司有强烈的兴趣，这样公司才会反过来“追”你，甚至愿意让步加价。即使后面双方意见不一致，也不至于留有坏印象。 对于一家公司，去什么样的小组，公司环境和发展机会，甚至公司的未来计划如何，都是选择Offer的重要因素。入职前，能从不同角度去看待公司，从不同的渠道收集信息，能提前预防你踩坑。 公司文化，可以参照各种新闻对公司的介绍。公司在意什么，领导强调什么，那就是他们的公司文化。说“好”就完事。 沉住气，不要当场答应 无论对方给出什么样的总包，即便是惊喜，即便是大牛公司，即便是你现在唯一的Offer，也不要立马答应，因为任何时候都是有讨价还价的地步。HR并不期望当场拿到答复，他们告诉你的同时也做好了收到拒Offer的消息。 对于HR，为了能促使你接受Offer，HR甚至会主动加价，沉住气没准你每年能拿到更多的钱。 多听少说 当你拿到Offer，进入了谈薪资的阶段时候，注意要多听少说。 HR行业门槛普遍较低，可以发现很多是文科出身，毕业没多久的妹子，当然这不包括经验老练的猎头。沟通，是一件细活，你需要留意她们说的每一句话，每一个字，也许她们无意之间会透露很多信息给你。沉默是金，让对方多揣测你的心思，出昏招。我们需要足够的信息来支撑我们接下来的谈判。 比如： 谈到薪资的时候，你沉默不语，她可能回了一句，“你对股票还满意么？”，你可以从中得出股票部分还有提升空间。 谈到部门招聘计划，HR答复有很大的招聘计划，你可以从中得出公司迫切填补当前的人力需求。综上这些，我们在接下来的谈判都会更有底气 书面确定工资数目 大部分的公司，会随着Offer会发一个正式的邮件通知。而有的公司，只会电话口头Offer。口头Offer，意味着缺少法律效应，即便入职后公司基于的薪资不一致，你也无从谈起。 为了防止公司“理解有误”，也为了防止公司“将来反悔”，我们还是要想方设法在入职前，拿到这份正式的Offer邮件。或者自己主动发送这封邮件，如果对方答复了，也是具有法律效应的。 关于程序员薪资组成，我会在后续出单篇描述。 按照自己的节奏进行 仅限于跳槽的同学们。对于第一份offer，自身还是比较被动的，只能适应他们的节奏。 HR往往乐意逼着我们接Offer，比如两天内给答复。对于这种，只有两个字，没门！至于拒绝的理由也是显而易见的，拖家带口、外地搬家（卖房子，子女上学，配偶工作等）、多份Offer(综合考虑) 牢记一个原则： 我们值得这个价，而且现在我们是在选择更好的机会,而不只是为了饭碗。公司如果想招揽我们，就需要拿出足够的诚意。 催其他公司给offer 谈判最有力的手段，就是多家公司竞价。 在收到A公司的Offer后，转头找B要Offer，催着他们，千万不要等着他们答复。如果A公司的Offer有分量，你可以跟B公司摆摆。在过程中，会有HR让你透露下其他Offer的薪资，你只要牢记对每家公司都透露，自己强烈的兴趣，再拿其他更高的Offer比较。没准公司就咬咬牙加价了。 整个过程，就跟菜市场讲价一样，如果你精通此道，那必定手到擒来。中间有很多细节需要自己慎重处理，但一定要内心强大，坚持下来，没准接下来你能谈出一辆奔驰🚗（就只动动嘴）。 七、offer的选择 Offer的选择，需要结合自己的情况思考。这里只是我个人的遇到的一些情况。 薪资， 薪资一般包括：基础工资（Base Salary)、奖金（Bonus)和期权（Stock）。 可以找个在线薪资计算器，大概计算每年的收益多少。以及包括税前税后的收入是否满足自己的期望。 五险一金， 国内和国外企业在这一方面的待遇相差较多，特别是住房公积金这一条。主要作为国内和国外企业Offer的考虑点。 上市公司， 相比没上市公司，存在很大的不确定性。如股票的估值，上市6个月后才能套现股票，以及公司的发展前景。当然，也存在等公司上市后，股票套现，实现财务自由。这点回到之前自己对公司的了解和发展的预判。 另外，假若如果只是考虑跳板因素，则更多的是考虑职位和领域，能给下一次提供更好的经验。 职位， 职位涉及的领域，决定了你下一份工作的方向和范围。选择的这段经历，将作为转行管理的跳板，未来高升的积累。这里建议多考虑长远目标。 凡是没有立即兑现的，都是虚无的，就当没有给。 画饼永远都是老板的手段，如果兑现了，得偿所愿。那没有兑现呢？你就真白打工了。 八、最后薅一把 无论对方给你什么数字，就算满足你的期望，也不建议你当场答应。玩的就是心理战，没准最后关头，公司给你加个红包，比如签字费涨几万等等。 >—— 码字不易，已阅留爪 (ฅ´ω`ฅ) ——","link":"/cheng-xu-yuan-mian-shi-gong-lue/interviewsalary/"},{"title":"Linux操作系统 —— 内核（二）","text":"本系列，是自己学习Linux过程中的笔记。希望读者在看完全文后，也能留下你们的经验或者问题。如果能从这里学到点东西，记得请我喝杯☕☕☕~ —— MinRam 一、前言 Overview 操作系统（Operate System) 是硬件的管家。 组装过个人电脑（Personal Compute)的朋友，一定知道一台完整的电脑主要包括： CPU, 内存条, 主板, 硬盘, 显示器, 鼠标/键盘, 显卡 在组装完这些硬件后，还需要安装一个操作系统，比如windows。在经过各种配置（折腾），最后完成了从硬件到可操作的计算机组装。最后装上QQ，加个群，愉快地在群里吹逼。 那么操作系统是如何管理这么多的组件，最后只需要通过鼠标和键盘，就能提供各种各样的服务呢？ 二、内核 Kernal 内核(Kernal), 是操作系统的心脏，可以理解是一家通过包装和管理硬件资源，为上层运行的软件提供简单便捷服务的公司。 以较合理的方式阐述内核的地位： 从技术层面讲：内核是硬件和软件的中间层。作用是将应用层序的请求传递给硬件，并充当底层驱动程序，对系统中的各种设备和组件进行寻址。 从应用层面讲：上层应用软件并不关心硬件，它最多只需要关心内核。内核是应用程序在系统中所能触碰的最底层。所以内核抽象了硬件，让应用感知不到实际硬件的逻辑细节。 内核是硬件的资源管理程序。负责将可用资源（CPU, Disk, RAM)分配到各个系统进程。 内核也基于系统调用子系统（System Call)提供了一整套系统操作库，让应用程序能像普通函数一样，调用系统接口。 系统主要由以下几个组成部分，由系统调用（系统调用子系统）统一管理。应用通过系统调用提供的函数接口与内核进行交互。用户应用程序执行的区域是用户空间，以下则是内核空间。 以上阐述，可能都听不懂，所以结合QQ应用，从打开到发消息吹逼，解释内核各组件的用途。 1. 设备管理子系统 （Device Management System） 计算机有各式各样的外接设备（鼠标，键盘，摄像头，音响）。这些设备都是由不同制造商制作的，但却都能在操作系统中适配。其关键就是设备管理子系统 操作系统的设备管理子系统，又叫做设备驱动系统。为了能够兼容这些各式各样的设备，系统将设备进行了抽象成几个动作（初始化/释放，读取设备上的信息，发送消息给设备，检测设备错误）。这样操作系统就不必去定义所有牌子的设备。 在Linux系统中，设备被分成：字符设备，块设备，网络设备。 在QQ的例子中，我们分成两类设备： 输入设备和输出设备。 输入设备，就是计算机给使用者（客户）提供的客户对接员（客服)，用来接受使用者（客户）的反馈。 鼠标/键盘，就是计算机的输入设备。我们通过移动鼠标，告知电脑，指针往哪个方向移动了多少，左键或者右键。又或者通过键盘，告知电脑，我们输入什么样的字符。如同公司的客服，配备销售、售前的岗位，与客户对接，把需求传递到后方。 而对于操作系统，鼠标/键盘对应的驱动（输入设备驱动），就是操作系统配备的客户对接员，用来解释设备传递过来的信息。同时这会给操作系统发送中断信号，告知操作系统需要停下来，听听使用者要干嘛。这个时候使用者发送消息的事件，为中断事件 Interrupt Event。 补充下硬件到软件的知识（以现在常见的USB接口鼠标为例）： 除了USB接口的鼠标外，还有PS/2和串口等，其信号流路径各不相同。 现在通过鼠标，能操作指针去打开QQ。 输出设备，就是计算机给使用者（客户）提供的产品交付员，用来给使用者（客户）反馈结果。 显示器 + 显卡，就是计算机的输出设备。将计算机处理结果展示给使用者（客户）。对于显卡和显示器，只知道在哪个坐标，展示什么图像（像素）。当鼠标移动时，不断的刷新指针的位置，重新绘制。 而对于操作系统，显卡驱动就是操作系统的产品交付员。 因此通过显示器，我们能知道指针到哪了，QQ的快捷键位置，以及QQ运行过程中的各种消息。 2. 文件管理子系统 (File Management System) 通过鼠标点击快捷键，发送中断事件，操作系统开始处理“指针点击QQ快捷键”事件。 在操作系统知道，指针点击了QQ的快捷键后，操作系统开始启动QQ。而这不再是简单的移动指针，不是零星的操作，于是系统选择单独立项，由单独的进程（项目组）来执行这个项目。 显然，立项就需要有完整的执行计划书，指导系统该怎么做，怎么执行，遇到各种情况该怎么办。而这些逻辑都被程序定义好，也就是由开发者设计并编写的代码，通过编译变成这份项目执行计划书（程序）。 这些程序，都是通过二进制被存放在计算机的存储设备上，也就是常说的硬盘。硬盘也是计算机的物理设备。在第一次使用时，会进行格式化 (对存储空间初始化)之后，就能存储这些文件。为管理这些文件，操作系统提供了文件管理子系统（File Management System)。就像存放项目计划书的档案室，有一定的归档格式，在需要的时候，可以拿到对应应用的程序。 从文件管理子系统中，我们拿到了QQ的程序。这只是一份二进制数据，指导QQ的运行逻辑。 在Linux系统中，有一个概念： 一切都是文件。Linux把各种资源都当作文件，包括硬件设备（对应设备文件）。所以Linux系统的根文件系统实现了虚拟文件系统（Virtual File System, VFS)。 3. 系统调用子系统 (System Call System) 系统调用，是操作系统上层应用进入内核的入口。 就跟项目的建立，需要项目组，人力，物力和流程审批一样。运行一个程序，需要CPU、内存、各种设备的调度。而资源的调度，就涉及到两个问题： 效率，时间就是金钱，不管是资源申请还是使用，都应尽可能高效。 权限，一个公司中会有多个项目，每个项目都有各自的权限。同样的每个程序都有各自的权限，普通程序不能访问机密程序的资源等。 效率，主要就是依靠操作系统的统一接口，统一的办事大厅，也就是系统调用。权限，则依靠操作系统的权限机制，例如linux的文件权限管理。 而QQ的启动，就需要通过系统调用，来调用进程管理子系统，创建新进程（Process)。 通过系统调用，我们为QQ建立起新进程，用来专门处理QQ的逻辑。 一旦项目(程序）正式立项，就要开始执行，就要成立项目组(进程），将开发人员（线程)分配到这个项目组(进程），按照项目执行计划书（代码）一步一步执行。 4. 进程管理子系统 (Process Management System) 通过进程管理子系统，创建了QQ进程。由文件系统中的静态程序转变成运行中的进程。 进程管理子系统的核心业务就是进程调度。在Linux内核中，它的调度单位就是进程，负责调度多个进程对CPU的访问，从而在宏观上，系统中的进程是并发的。除了上面提到的创建新进程（fock,exec)，进程调度子系统还提供了结束进程（kill,exit)，控制进程，同步进程以及进程间通讯的接口。 CPU的处理线程就好比开发人员，多个进程就是一个个项目，进程管理子系统就像项目经理，负责调度项目到开发人员手上进行。 进程和程序的区别： 程序： 存放在硬盘（存储设备）上的一段代码和数据的可执行镜像，是一个静态的实体，并不会有任何变化。 进程： 是一个执行中的程序，由CPU执行，在根据代码的逻辑，动态变化的实体。 通过进程管理子系统，为QQ建立一个进程（项目组），为这个进程提供可用的CPU（开发人员） 5. 内存管理子系统 (RAM Management System) 通过内存管理子系统，保证系统各个进程安全访问内存区域。 在Linux系统中，内存管理子系统保证各个进程有自己独立且私密的内存空间，同时也实现了虚拟内存到物理内存的转换，以及系统的可用空间。 每个项目组都需要自己的会议室，自己的草稿白板，同时应该具备一定的保密性，避免被其他项目组看到。所以内存管理子系统，又像是会议室管理系统 内存管理的硬件按照分页方式管理内存，分页就是把系统的物理内存按照相同大小等分，每个内存分片称作内存页，通常内存页大小是4KB。 内存管理子系统要管理的不仅是4KB缓冲区，它提供了对4KB缓冲区的抽象，例如slab分配器。这种内存管理模式使用4KB缓冲区为基数，然后从中分配管理结构，并跟踪内存页使用情况 ，系统中哪些内存页是满的，哪些内存页面为空，哪些内存页没有完全使用。这样一来，系统就支持动态调整内存使用情况。 补充一点，Linux是支持内存交换的，因为Linux中使用的是虚拟内存，当物理内存不足时，内存管理子系统会将内存暂时移到磁盘中，在物理内存充裕时又将内存页从磁盘移到物理内存中，这就是内存交换。而在32bit的系统上，每个进程都最大享有4GB的内存空间，因为由于32bit的系统寻址空间只有4G，当然这是虚拟内存，0~3GB是属于用户内存空间，3GB以上的则是属于 系统内存空间，实际上用户的程序几乎使用不完那么大的用户空间，一旦超出将无法正常运行，当然系统内存空间与用户内存空间是可以调整的。 6. 网络子系统 (Network System)网络子系统，主要是为了同其他机器进行通讯，因此操作系统常常将与网络相关的代码被Linux独立开，形成一个相对独立的子系统，称为网络子系统。 后续会有单独一章讲解。 三、总结 Summary综上，整个内核大致功能就是这些，这里只是简单讲下后续单独展开各子系统运行逻辑。 四、引用 Reference [1] Linux Device Driver","link":"/linux-cao-zuo-xi-tong/operationsystem-02-kernel/"},{"title":"Linux操作系统 —— 设计目标（三）","text":"本系列，是自己学习Linux过程中的笔记。希望读者在看完全文后，也能留下你们的经验或者问题。如果能从这里学到点东西，记得请我喝杯☕☕☕~ —— MinRam 一、前言 Overview在上文的内核篇，我们可以知道，操作系统（Operate System)就是在管理各种物理资源，如中央处理器CPU、内存memory、磁盘disk等，并对他们进行抽象，虚拟化。 操作系统，提供了高并发能力(Concurrency)，以及长期且安全的数据存储能力。 在了解操作系统的设计细节时，需要了解操作系统的原则，或者说时系统的目标，协助我们理解实现逻辑的优缺点。 二、设计目标2.1 概念抽象 Abstraction 抽象，是IT界内一门极其重要的能力。从系统设计到代码开发，无处不在。 抽象，是一种展现其外观而隐藏其实现细节的手段。因而，我们才能通过对复杂功能的抽象和细化，设计出复杂的操作系统。例如： 操作系统，就是对硬件细节进行抽象，并提供接口给上层程序；进程、虚拟内存、文件等这些概念，则是对相应资源或者数据的抽象。 C语言，就是对底层系统操作的抽象，我们在进行编码的时候并不需要知道实际机器语言的代码是如何被执行。 2.2 高性能 Performance 系统，是硬件的管家，需要提供较高的硬件使用效率。 换种说法，就是操作系统应尽可能少的占用硬件资源。上文讲到，系统内核是对硬件的虚拟化（Virtualization）,CPU, 内存，磁盘等等，为上层用户程序提供通用的接口。但整个虚拟化过程并非是没有性能损耗的，如CPU在各个进程切换时，需要重新加载上下文。所以在设计系统新特性时，应考虑代码量，运行耗时，存储需求（内存和磁盘）等。 2.3 应用隔离 Protection between applications 在系统上，同一时间会有多个程序在同时运行。 系统应实现处理好应用之间的关系，也包括应用同系统的关系，。换个说法就是系统应保护各个用户程序的空间不受其他用户程序侵犯。为了保证系统上能同时运行多个程序，我们不希望恶意程序去影响正常程序，甚至影响到系统的正常运行。例如进程管理系统中的僵尸进程和孤儿进程。 2.4 高可靠性 Reliability 系统往往追求高可靠性。 操作系统，应保证高比例的可靠性。当用户程序出问题时，我们并不希望系统因此就宕机。这样才能继续支持其他正常程序的运行。 在上百万行代码中，保证系统能有较高的可靠性和异常处理能力，具有极大挑战。 2.5 其他 Others除了以上重要目标外，基于操作系统的承载硬件的不同，还会有不同的额外目标： 能源使用效率：针对于环保节能理念，以及应对移动办公的需求，电量往往是有限的。因而需要考虑合理分配剩余电量，如CPU降频，散热系统降级和降低显示器亮度等方案。 安全: 针对恶意软件的防护隔离，特别是高速网络的出现。 移动便携性：从个人台式电脑，到笔记本，再到手机，再到穿戴设备等，移动需求越来越必要。如支持触屏等。 三、总结 没有完美的方案，只有更好的方案 对于以上每一项技术目标，每个人都会有自己的考量和最终的方案。而实际运用到操作系统中的，要么采用，要么替代更新。方案并不可能完美，只会不断的优化，以及接受长期的考量，最后被广泛采用的那个则是在总体上成本低，收益高（性能以及其余实际因素）的折中方案。 要想出一个方案的大致思路还算简单，在有经验的支持下，通过直觉或是其他问题的参照。 除了这类方法，最简单的方式就是将总多较好方案的进行结合，这一方法成为杂合方法（Hybrid-Approach).如在IT界内，段页式内存、两段锁、设备交互协议等。这样的方法自然比不过在深刻理解一个问题后得出的新的更统一的解决方案，但是它是能在已有方案下快速提升收益的手段。","link":"/linux-cao-zuo-xi-tong/operationsystem-03-designgoal/"},{"title":"Linux操作系统 —— 进程（四）","text":"本系列，是自己学习Linux过程中的笔记。希望读者在看完全文后，也能留下你们的经验或者问题。如果能从这里学到点东西，记得请我喝杯☕☕☕~ —— MinRam 一、前言 Overview 进程，就是运行的程序。 进程 Process, 是操作系统提供给用户程序的一种抽象概念。内核篇讲过，程序本身是静态的一串代码，且存放在磁盘。在需要的时候由操作系统，将程序从磁盘中拿出，进行一系列操作后，程序开始运行，也就是进程。 而在操作系统中，往往会同时运行多个程序，浏览器、IDE、聊天工具等等，在现代操作系统中，往往会有几十个程序同时在跑。每个运行中的程序都需要跟CPU进行交互处理各式各样的计算任务。而CPU往往只有几个有限的核心。 面对这种僧多粥少的问题，操作系统给用户程序提供了CPU虚拟化技术，其目的就是产生无限多的CPU的假象，让每个用户程序觉得自己独占一个CPU核心。这一实现方式就是采用时分共享（time sharing)实现的。这一技术的基础调度单位就是进程。 可以看出，进程就是系统对CPU进行抽象，提供给应用程序使用。用户应用程序只跟进程打交道，无法触碰到实际CPU。而操作系统中进程管理子程序，也只关注进程这个抽象，再将它分配给实际CPU核心。这样用户程序并不需要关心当前有没有CPU可以用，而操作系统也不需要关心用户程序需不需要使用CPU。就这样操作系统实现了多个用户应用程序之间复用同一个或者多个CPU核心。 时分共享的机制，也运用在其他类型的资源上。 二、进程 Process 进程，程序的实例 2.1 进程的组成对于操作系统来说，运行中的程序就是进程。我们可以通过了解进程运行过程中的一系列行为和操作，来了解进程。 那么需要了解对于执行进程来说，什么是需要我们关注的。所以进程由以下几个部分组成： 进程标识 Process ID. 进程的标识符，除了本身的PID以外，还应当记录父进程的Parent PID。 进程状态 State 进程状态. 虚拟内存地址空间 Address Space. 包括主存（用户空间、内核空间）、寄存器（一般寄存器、控制寄存器）、外部设备（文件、socket、其他内存映射IO设备）等. 程序的数据和变量都是存储在内存上，而程序本身的指令也是存在内存里的。也就是说整个进程都是位于内存上的。所以这一段内存的访问地址，就是进程的一部分。 寄存器 Register. 特指特别功能范畴的寄存器，如程序计数器（Program Counter），也被叫做指令指针（Instruction Pointer)，属于CPU寄存器，指向下一条指令所在的内存地址。还有栈指针（Stack Pointer) 和函数栈指针（Frame Pointer)，则是用来指明函数入口参数，本地变量，以及范围值地址。 外接设备信息 I/O infromation. 程序在运行中，可能会读取或者写入一些文件(如磁盘，U盘中的文件),并对其进行独占等操作，所以进程中还需有这些文件列表信息。 2.2 进程的生命周期对于操作系统，它提供了一些进程的操作接口API，也就对应了进程的生命周期： 创建 Create. 进程可以通过多个途径被创建出来，如终端，双击快捷键。系统就会调用起一个进程。/ 销毁 Destroy. 有生就有死，操作系统必须有途径能强制性地销毁一条进程。正常情况下，在进程代码执行完后，往往会自行推出（exit)。但考虑到异常情况（如死循环，死锁）下，操作系统也能为用户提供销毁的接口（如linux的kill指令） 等待 Wait. 有时候进程需要等待另一个进程的结束，也就是阻塞进程。 其余操作 Miscellaneous Control. 除了销毁等待，操作系统还提供了其他的操作接口比如挂起（Suspend）和对应的恢复（Resume) 状态 Status. 操作系统会提供一些接口，用来查询进程的运行状态，运行时常，PID等信息。 linux下对进程的API有以下几种（后续会详细介绍）： 2.3 进程的状态随着操作系统发展，进程状态也在不断细分，但最基础的也是以下几种： 创建状态 Creating. 前面讲到，在进程创建时，需要申请一块空白的进程控制块(PCB Process Controll Block)。并在向其中填写控制和管理进程的信息，完成资源分配。如果创建工作无法完成，比如资源无法满足，就无法被调度运行，把此时进程所处状态称为创建状态。进程的生命周期开始 就绪状态 Ready. 在进程拿到所需资源后，就进入就绪态。这里包括创建准备完成，还有等待条件完成的进程。当进程处于就绪状态时，意味着进程随时可以被CPU激活进入执行状态。但由于执行策略的结果，没有被选中进入执行状态。 执行状态 Running. 进程正在被执行，根据进程的指令执行相应的操作。 阻塞状态 Blocked. 正在执行的进程由于某些事件（I/O请求，申请缓存区失败）而暂时无法运行，进程受到阻塞。在满足请求时进入就绪状态等待系统调用。例如，当进程写入或者读取文件时，会等待I/O请求，这时候就会进入阻塞状态，而处理器就会去执行其他进程。 终止状态 Dead. 进程结束，或出现错误，或被系统终止，进入终止状态。进程的生命周期结束 所以可以看出，进程的核心状态只有三种： 就绪Ready、执行Running、阻塞Blocked。但为用户观察需要，进程还有挂起和激活两种操作。挂起后进程处于静止状态进程不再被系统调用，相反操作则是激活操作。这里不再补充 三、 源码剖析 Code 以Linux内核v5.13.16为例，且依赖库为X86（随便找的版本）。本节需要有一定的代码语法知识，特别是C语言。 操作系统，本身就是一个程序。同样有一些关键的数据结构，用来存储进程状态信息。其内容与上面谈到的逻辑大致一致，但也有具体的实现改动。以下结合代码，比较实际应用中的区别。 首先需要解释下Linux中，进程和线程的区别。在Linux操作系统层面，线程就是特殊的进程，在于跟其他同进程下的线程共享内存空间（代码段，数据段，但不共享栈）。在用户层面来说，进程和线程是两种不同的概念。而在内核层面中，线程其实也是进程。所以对于Linux内核来说，只有任务TASK这个概念。后续会单独出一章博客完整说明下Task定义。 回归开头，在Linux中，每个线程都是一个Task，也都是通过task_struct结构体来描述的，我们称它为进程描述符。内核进程相关源码链接（source/include/linux/sched.h）。它包含了如下几个内容： 标识符 ： 唯⼀标⽰符，⽤来区别其他Task(线程）。 状态 ： Task当前状态。 优先级 ： 用于调度用的优先级。 程序计数器： Program Counter程序中即将被执⾏的下⼀条指令的地址。 内存指针： 包括程序代码和线程相关数据的指针，还有和其他线程共享的内存块的指针 上下文数据： 线程执⾏时处理器的寄存器中的数据。 I／O状态信息：包括显⽰的I/O请求,分配给线程的I／O设备和被线程使⽤的⽂件列表。 运行信息： 包括处理器时间总和，使⽤的时钟数总和，时间限制等。 3.1 进程标识符 Process ID 进程标识符相关源码链接（source/include/linux/sched.h） 截取片段代码如下： 1234struct task_struct { pid_t pid; pid_t tgid;} 前面讲到，对于Linux系统内核来说，只有线程和线程组。同一线程组内的线程共享内存空间（代码段，数据段，但不共享栈）。所以线程组就是进程的概念。 在task_struct中，pid(Process ID)就是指线程的唯一标识，而tgid(Task Group ID)就是线程组的唯一标识。 当创建一个新进程时，会先创建进程的主线程，主线程获取自己的PID，同时主线程的PID就是这个线程组（进程）的唯一标识TGID。 当一个线程启动一个新线程时，新线程会获取自己的PID，同时从原始线程继承TGID 当我们用ps命令或者getpid()等接口查询进程ID时，内核返回给我们的也正是这个tgid。注意不是pid pid 和 tgid 都是 pid_t 类型，该类型是由各体系type.h分别定义的__kernel_pid_t，通常是一个 int 类型，参考include/uapi/asm-generic/posix_types.h。 截取部分代码如下：1234567// tags/v5.13.16 - include/linux/types.htypedef __kernel_pid_t pid_t// tags/v5.13.16 - include/uapi/asm-generic/posix_types.h#ifndef __kernel_pid_ttypedef int __kernel_pid_t;#endif 在threads.h可以看到关于PID默认情况下最大值的定义。 1234/* * This controls the default maximum pid allocated to a process */#define PID_MAX_DEFAULT (CONFIG_BASE_SMALL ? 0x1000 : 0x8000) 3.2 内核进程状态 Process Status 进程状态相关源码链接（source/include/linux/sched.h） 截取状态成员如下：123456struct task_struct { /* -1 unrunnable, 0 runnable, &gt;0 stopped: */ volatile long state; int exit_state;} Task的主要状态由task->state确定，当进程退出后，会再task->exit_state同步更新。 截取状态定义代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445/* * Task state bitmask. NOTE! These bits are also * encoded in fs/proc/array.c: get_task_state(). * * We have two separate sets of flags: task-&gt;state * is about runnability, while task-&gt;exit_state are * about the task exiting. Confusing, but this way * modifying one set can't modify the other one by * mistake. *//* Used in tsk-&gt;state: */#define TASK_RUNNING 0x0000#define TASK_INTERRUPTIBLE 0x0001#define TASK_UNINTERRUPTIBLE 0x0002#define __TASK_STOPPED 0x0004#define __TASK_TRACED 0x0008/* Used in tsk-&gt;exit_state: */#define EXIT_DEAD 0x0010#define EXIT_ZOMBIE 0x0020#define EXIT_TRACE (EXIT_ZOMBIE | EXIT_DEAD)/* Used in tsk-&gt;state again: */#define TASK_PARKED 0x0040#define TASK_DEAD 0x0080#define TASK_WAKEKILL 0x0100#define TASK_WAKING 0x0200#define TASK_NOLOAD 0x0400#define TASK_NEW 0x0800#define TASK_STATE_MAX 0x1000/* Convenience macros for the sake of set_current_state: */#define TASK_KILLABLE (TASK_WAKEKILL | TASK_UNINTERRUPTIBLE)#define TASK_STOPPED (TASK_WAKEKILL | __TASK_STOPPED)#define TASK_TRACED (TASK_WAKEKILL | __TASK_TRACED)#define TASK_IDLE (TASK_UNINTERRUPTIBLE | TASK_NOLOAD)/* Convenience macros for the sake of wake_up(): */#define TASK_NORMAL (TASK_INTERRUPTIBLE | TASK_UNINTERRUPTIBLE)/* get_task_state(): */#define TASK_REPORT (TASK_RUNNING | TASK_INTERRUPTIBLE | \\ TASK_UNINTERRUPTIBLE | __TASK_STOPPED | \\ __TASK_TRACED | EXIT_DEAD | EXIT_ZOMBIE | \\ TASK_PARKED) 可以看到基础进程状态的标识码都是采用long类型的，且都是2的幂。这是状态的标准处理方式。我们可以通过逻辑运算-或（OR |)来创建更多的组合状态，也可以用逻辑运算-与（AND &amp;)来验证。所以对于通用32位系统，我们最多只有32种基础状态。例如：#define EXIT_TRACE (EXIT_ZOMBIE | EXIT_DEAD) Linux中进程状态的基础状态（TASK_RUNNING，TASK_INTERRUPTIBLE，TASK_UNINTERRUPTIBLE，__TASK_STOPPED，__TASK_TRACED，EXIT_DEAD，EXIT_ZOMBIE），又分为两类： state(运行中的状态) 和 exit_state(退出状态)。 TASK_RUNNING 表示进程处于执行状态或者就绪状态。进程处于TASK_RUNNING时，并不意味着进程处于执行状态。只有被current指向的进程才是执行中的进程。 系统中有一个运行队列（Run_Queue)，存放处于TASK_RUNNING状态的进程。在系统执行调度进程时，会从该运行队列中选择符合条件的进程。current永远指向运行队列中的某个进程。 TASK_INTERRUPTIBLE 表示进程处于阻塞状态，在等待某个资源或某个事件（比如等待Socket连接、等待信号量）。当这些事件发生时（由外部中断触发、或由其他进程触发），对应的等待队列中的一个或多个进程将被唤醒，转成TASK_RUNNING。 通过ps的指令我们可以看到进程列表的大部分的进程都是处于该状态下。在阻塞状态的进程，都位于系统的等待队列（Wait_Queue）中。 TASK_UNINTERRUPTIBLE 表示进程处于阻塞状态。不同于TASK_INTERRUPTIBLE的是，该状态下的进程是不可中断的。不可中断，指的是进程不响应异步信号，指的并不是CPU不响应外部硬件的中断。 Linux中阻塞状态的进程分为两种：可中断（TASK_INTERRUPTIBLE）和不可中断（TASK_UNINTERRUPTIBLE）的阻塞状态。 TASK_INTERRUPTIBLE： 如果收到信号，该进程就从等待状态进入可运行状态，并且加入到运行队列中，等待被调度。也可以接受kill指令异步给的信号。 TASK_UNINTERRUPTIBLE: 往往因为硬件资源不能满足而阻塞，例如等待特定的系统资源，它任何情况下都不能被打断，只能用特定的方式来唤醒它，例如唤醒函数wake_up()等。 而TASK_UNINTERRUPTIBLE状态存在的意义就在于，保护内核的某些处理流程是不被打断。如果进程响应异步信号，程序的执行流程中就会被插入一段用于处理异步信号的流程（这个插入的流程可能只存在于内核态，也可能延伸到用户态），于是原有的流程就被中断了。 在进程对某些硬件进行操作时（比如进程调用read系统调用对某个设备文件进行读操作，而read系统调用最终执行到对应设备驱动的代码，并与对应的物理设备进行交互），可能需要使用TASK_UNINTERRUPTIBLE状态对进程进行保护，以避免进程与设备交互的过程被打断，造成设备陷入不可控的状态。这种情况下的TASK_UNINTERRUPTIBLE状态总是非常短暂的，通过ps命令基本上不可能捕捉到。 应注意，部分工程师喜欢将进程设置为TASK_UNINTERRUPTIBLE，将导致一系列问题。当唤醒条件无法满足时候，进程是无法接受的异步指令的。最终只能通过重启系统解决。一方面，您需要考虑一些细节，因为不这样做会在内核端和用户端引入 bug。另一方面，您可能会生成永远不会停止的进程（被阻塞且无法终止的进程）。所以Linux Kernel在2.6.25引进了新状态TASK_KILLABLE，解决这一问题。 TASK_KILLABLE TASK_KILLABLE = TASK_UNINTERRUPTIBLE + TASK_WAKEKILL 表示进程处于阻塞状态。跟TASK_UNINTERRUPTIBLE类似，该下的进程是不可中断的。但又为了弥补TASK_UNINTERRUPTIBLE的缺陷（唤醒条件无法满足）。该状态下的进程只接受终止信号的异步信息，其余一概不接受。 __TASK_STOPPED 表示进程被暂停了。通常当进程（TASK_UNINTERRUPTIBLE状态下的进程除外）接收到SIGSTOP、SIGTSTP、SIGTTIN或SIGTTOU信号后就处于这种状态。例如，正接受调试的进程就处于这种状态。当进程接收到SIGCONT后，则恢复到TASK_RUNNING状态。 对于该状态的进程，仍处于系统的运行队列中。但调度器并不会去执行该进程。 __TASK_TRACED 表示进程被暂停了，且被Debugger程序监听跟踪。正在被跟踪，指进程暂停，等待调试进程对它进行其他操作。比如gdb中对跟踪进程标记断点后，进程运行到断点处代码，就会处于TASK_TRACED状态。 TASK_TRACED和TASK_STOPPED都是表示进程被暂停。TASK_TRACED中的进程无法被SIGCONT信号唤醒。只能等到调试进程通过Ptrace系统调用执行PTRACE_CONT、PTRACE_DETACH等操作（通过Ptrace系统调用的参数指定操作），或调试进程退出，被调试的进程才能恢复TASK_RUNNING状态。也就是TASK_TRACED其实是对调试进程的保护，避免被错误信号恢复执行状态。 EXIT_ZOMBIE 表示进程已经终止了。但还未被父进程通过wait()调用获知该进程的终止信息,又被称为Zombie的数据结构。 该状态的进程是非常特殊的一种，它已经放弃了几乎所有内存空间，没有任何可执行代码，也不能被调度，仅仅在进程列表中保留一个位置，记载该进程的退出状态等信息供其他进程收集，除此之外，僵尸进程不再占有任何内存空间。在进程退出后，会进入该状态，就是EXIT_ZOMBIE的进程在等待父进程采集终止信息中。 该状态的进程不可通过kill清理。如果要清理该进程，要么等到采集时间超时，或者清除父进程。由于该进程还保留PID，过多的僵尸进程，会影响系统的调度效率。 EXIT_DEAD 表示进程的最终状态。 状态转移图： 3.3 内核进程信息 Address of Process在Linux中，线程有三种重要的数据结构，分别是内核栈、线程描述符和线程联合体。三者的关系，可以参考下图： 进程相关源码链接（source/include/linux/sched.h） task_struct，是内核下进程描述符，包含了具体进程的所有信息。 源码可以参考文件/include/linux/sched.h,截取部分代码如下。其中包含了thread_info和stack。还将主体成员包含在randomized_struct_fields中，具体原因可以参考3.4节。 123456789101112131415161718192021222324struct task_struct {#ifdef CONFIG_THREAD_INFO_IN_TASK /* * For reasons of header soup (see current_thread_info()), this * must be the first element of task_struct. */ struct thread_info thread_info;#endif /* * This begins the randomizable portion of task_struct. Only * scheduling-critical items should be added above here. */ randomized_struct_fields_start void *stack; ... /* * New fields for task_struct should be added above here, so that * they are included in the randomized portion of task_struct. */ randomized_struct_fields_end} thread_info，是每个架构对进程（内核视角下）的具体实现信息。 内核需要存储每个进程的控制块PCB信息，同时Linux要兼容不同的架构（x86，ARM等），每个架构有自己独特的进程信息结构。所以需要有一个方式，将架构相关的内容与Linux进程管理通用部分解耦分离。 用一种解耦的方式来描述进程, 就是task_struct, 而thread_info类型就保存了各架构自己需要的信息,同时我们还在thread_info中嵌入指向task_struct的指针, 则我们可以很方便的通过thread_info来查找task_struct。 task_struct结构里面通过CONFIG_THREAD_INFO_IN_TASK宏来控制是否有thread_info成员结构。 thread_info结构体的内容和具体的体系架构有关，保存了为实现进入、退出内核态的特定架构的汇编代码段所需要访问的部分进程的数据，所以大多数架构采用了独立寄存器或栈寄存器来保存thread_info地址。 下面是ARM体系下的thread_info结构，详见源码。 12345678910111213141516171819202122232425262728/** low level task data that entry.S needs immediate access to.* __switch_to() assumes cpu_context follows immediately after cpu_domain.*/struct thread_info { unsigned long flags; /* low level flags */ int preempt_count; /* 0 =&gt; preemptable, &lt;0 =&gt; bug */ mm_segment_t addr_limit; /* address limit */ struct task_struct *task; /* main task structure */ __u32 cpu; /* cpu */ __u32 cpu_domain; /* cpu domain */#ifdef CONFIG_STACKPROTECTOR_PER_TASK unsigned long stack_canary;#endif struct cpu_context_save cpu_context; /* cpu context */ __u32 syscall; /* syscall number */ __u8 used_cp[16]; /* thread used copro */ unsigned long tp_value[2]; /* TLS registers */#ifdef CONFIG_CRUNCH struct crunch_state crunchstate;#endif union fp_state fpstate __attribute__((aligned(8))); union vfp_state vfpstate;#ifdef CONFIG_ARM_THUMBEE unsigned long thumbee_state; /* ThumbEE Handler Base register */#endif}; 在thread_info结构中，嵌入了指向task_struct的成员task，方便我们通过该结构获取task_struct。 current相关 对于所有Linux兼容的架构，都必须实现current和current_thread_info两个宏定义。 current_thread_info 可以获取当前执行进程的thread_info实例指针 current 给出当前进程进程描述符task_struct的地址，通常由current_thread_info确定 task_struct中的stack是个void类型的指针，指向进程（内核视角）对应的thread_union thread_union是Linux将内核栈和线程描述信息thread_info组合成一个union。 详见源代码（source/include/linux/sched.h）。 123456789union thread_union {#ifndef CONFIG_ARCH_TASK_STRUCT_ON_STACK struct task_struct task;#endif#ifndef CONFIG_THREAD_INFO_IN_TASK struct thread_info thread_info;#endif unsigned long stack[THREAD_SIZE/sizeof(long)];}; 内核定义一个联合体thread_union用于将内核栈和thread_info存储在THREAD_SIZE大小的空间里，如果没有启用 CONFIG_ARCH_TASK_STRUCT_ON_STACK，那么联合体还会包含了一个task_struct结构。 THREAD_SIZE指thread_union的空间大小。 源码详见arch/(架构名称)/include/asm/thread_info.h, 该值与架构类型有关。 例如，arm(arch/arm/include/asm/thread_info.h)中的定义如下： 12345678910#ifdef CONFIG_KASAN/** KASan uses a lot of extra stack space so the thread size order needs to* be increased.*/#define THREAD_SIZE_ORDER 2#else#define THREAD_SIZE_ORDER 1#endif#define THREAD_SIZE (PAGE_SIZE &lt;&lt; THREAD_SIZE_ORDER) 从上面的定义可知，如果PAGE_SIZE的大小是4K的话，那么THREAD_SIZE就是8K。 thread_union中的stack 指进程的内核栈 进程在内核态运行时需要自己的堆栈信息（不是原用户空间中的栈）, 因此Linux内核为每个线程都提供了一个内核栈kernel stack, 用户态进程所用的栈，是在进程线性地址空间中；而内核栈是当进程从用户空间进入内核空间时，特权级发生变化，并切换堆栈，那么在内核空间中使用的就是这个内核栈。 注意task_struct中的stack并非指向内核栈，而是指向thread_union的地址。 thread_info和内核栈虽然共用了thread_union结构, 但是thread_info大小固定, 存储在联合体的开始部分, 而内核栈由高地址向低地址扩展, 当内核栈的栈顶到达thread_info的存储空间时, 则会发生栈溢出。 sp 栈寄存器，用来存储当前栈顶地址。 以x86源码为例，arch/x86/include/asm/asm.h 1234567/** This output constraint should be used for any inline asm which has a &quot;call&quot;* instruction. Otherwise the asm may be inserted before the frame pointer* gets set up by the containing function. If you forget to do this, objtool* may print a &quot;call without frame pointer save/setup&quot; warning.*/register unsigned long current_stack_pointer asm(_ASM_SP); sp寄存器是CPU栈指针，用来存放栈顶单元的地址。在 x86 系统中，堆栈从顶部开始，并朝着该内存区域的开头增长。从用户态切换到内核态后，进程的内核栈总是空的。因此，sp 寄存器指向这个堆栈的顶部。一旦数据写入堆栈，sp 的值就会递减。 通过sp，可以拿到thread_info的地址，即在current点讲到的current_thread_info。 12345678910static inline struct thread_info *current_thread_info(void) __attribute_const__;static inline struct thread_info *current_thread_info(void){ return (struct thread_info *) (current_stack_pointer &amp; ~(THREAD_SIZE - 1));}#define THREAD_SIZE_ORDER 1#define THREAD_SIZE (PAGE_SIZE &lt;&lt; THREAD_SIZE_ORDER) THREAD_SIZE 为 8K，其二进制表示为0000 0000 0000 0000 0010 0000 0000 0000。~(THREAD_SIZE-1)的结果正好是1111 1111 1111 1111 1110 0000 0000 0000。低十三位全为零，也就是sp的低十三位刚好被屏蔽，最终得到thread_info的地址。 当内核态线程使用了更多的栈空间时，内核栈会溢出到thread_info部分，因此内核提供了kstack_end函数来判断是否在正确的内核栈空间里。参照源码/include/linux/sched/task_stack.h 123456789#ifndef __HAVE_ARCH_KSTACK_ENDstatic inline int kstack_end(void *addr){ /* Reliable end of stack detection: * Some APM bios versions misalign the stack */ return !(((unsigned long)addr+sizeof(void*)-1) &amp; (THREAD_SIZE-sizeof(void*)));}#endif 3.4 内核进程其他 Others记录一些源码中的亮点： randomized_struct_fields_start&amp;randomized_struct_fields_end Linux内核在 4.13 中引入 Structure Randomization技术来随机化 task_struct 的大部分结构成员布局，用来防止利用结构体偏移来覆盖特定敏感字段（如函数指针）的内核攻击，有兴趣的可以看下这篇文章 Randomizing structure layout。 一个struct的内部数据存储是按照声明顺序的，因此黑客程序可以很容易得计算出一个关键值，比如跳转函数地址在内核一些结构体中的偏移。修改该偏移的值以后，就可以轻松控制内核执行自己的代码(内核态)。 举例代码： 123456struct critical_struct { int id; void (* fn) (void *data); void *data; ... }; 有这么一段内核源码，如果入侵程序获得了对应数据段的写权限，那么他可以通过$STRUCT_OFFSET + 0x04，也就是fn的函数地址修改为自己的代码地址，进而获得内核态的执行权限。如果混淆以后，就为这种侵入过程制造了难度。 3.5 进程相关指令 Process Commands补充下进程相关的简单指令 ps 描述： ps命令来自于英文词组”process status“的缩写，其功能是用于显示当前系统的进程状态。使用ps命令可以查看到进程的所有信息，例如进程的号码、发起者、系统资源使用占比（处理器与内存）、运行状态等等。帮助我们及时的发现哪些进程出现僵死或不可中断等异常情况。 语法格式： ps [参数] ps -eLf可以看到线程信息，其中PID指进程ID，LWP指线程ID（task_struct中的pid)。 top 描述： Linux中常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，常用于服务端性能分析。 语法格式： top [参数] 默认top，上会显示对应的进程数 top -H(也可以在进入界面后，再输入大写H)，可以看到线程数。 htop 描述： htop是Linux系统中的一个互动的进程查看器，一个文本模式的应用程序(在控制台或者X终端中)，需要ncurses。htop比较人性化。它可让用户交互式操作，支持颜色主题，可横向或纵向滚动浏览进程列表，并支持鼠标操作。 语法格式： htop [参数] 要在htop中启用线程查看，开启htop，然后按F2来进入htop的设置菜单。选择Setup栏下面的Display options，然后勾选Tree view和Show custom thread names选项。按F10退出设置。 推荐几个不错的文档网站： Linux命令大全(手册). 中文文档 Explain Shell . 英文文档，可能需要梯子。 四、总结 Summary所以进程大致内容就是这些，也是操作系统最基础的抽象概念。简单来说就是运行的程序。接下来会继续阐述进程的其他机制，如系统调用和调度算法。从而了解操作系统是如何实现CPU虚拟化的。 如内容有错误，或不足，请留言或者直接联系我。万分感谢指正。","link":"/linux-cao-zuo-xi-tong/operationsystem-04-process/"},{"title":"Linux操作系统 —— 进程API（五）","text":"本系列，是自己学习Linux过程中的笔记。希望读者在看完全文后，也能留下你们的经验或者问题。如果能从这里学到点东西，记得请我喝杯☕☕☕~ —— MinRam","link":"/linux-cao-zuo-xi-tong/operationsystem-05-processapi/"},{"title":"简单系统设计 —— 缓存（三）","text":"本系列，是自己学习Grokking the System Design过程中的笔记。希望读者在看完全文后，也能留下你们的经验。我万分荣幸能收到你们的消息。如果能从这里学到点东西，记得请我喝杯☕☕☕~ —— MinRam 一、前言 Overview 负载均衡 帮助我们在节点不断增多的系统上进行水平扩展。而缓存 是帮我们利用现有资源，减少成本较大的逻辑处理。 缓存就是系统的短期记忆。 每一次从后端拿到的数据很有可能再次被使用，那么通过消耗一定的存储空间（内存等），当我们再次需要数据的时候，我们可以直接从存储空间获取，而不是从后端再次申请。这将节省我们很多成本。 二、在系统中的位置 Position 缓存在很多地方都可以看到，例如硬件上的CPU缓存，操作系统中内存，浏览器上的页面缓存，Web应用上的Redis等 在分布式系统中，缓存往往会使用在较前端的部分，来最大限度的降低下游的请求压力。前面提到，当我们可以直接从缓存拿到数据的时候，就不再需要往下游请求数据。 三、类型 Cache Type大多数系统主要应用几种类型的缓存： 3.1 应用服务缓存 Appliation Server Cache在请求层的应用服务器上放置缓存，同时会配置一个本地存储用于暂放请求数据。 对于服务器每次需要发送的请求时，会先检查本地存储中是否已有。如果存在，直接从本地快速获取。若不存在，再发送请求去获取索要的数据。 本地存储可以是内存（如Memcached和Redis）或者是磁盘。内存的速度显然比硬盘快几个量级 3.2 数据库缓存 Database Cache 不同于应用服务器缓存所依赖的外部缓存机制（如Redis)， 数据库自身也存在缓存。 数据库的数据分为两种： 冷数据：通常存储在磁盘上且不经常查询的数据。 热数据：频繁查询的数据，会被缓存在内存中。 通过某些级别的配置，可以针对数据库读写模型，在不更改业务代码的情况下就能提供更好的性能。而这就靠DBA或者运维工程师的功底。 笔者在数据库缓存方面并没有太多的经验，不再扩展，待后续补充。 3.3 内容分发网络 CDN 内容分发网络 Content Delivery Network = 更智能的镜像服务器 + 缓存 + 流量导控 CDN 简单来讲就是将内存缓存在离用户更近的地方。采用更多的缓存服务器（CDN边缘节点），布置在用户访问相对集中的地区或网络中。当用户访问网站时，利用全局负载，将访问重定向到用户最近的缓存服务器上。由缓存服务器响应响应的请求。 CDN 将我们的应用服务器从大量的静态资源请求解放出来。对于图片，静态HTML，CSS等的资源，则从CDN节点直接获取。应用服务器将更专注于业务动态处理。 如果我们的站点还不够大，则可以通过像Nginx这样的轻量级HTTP服务器，从单独的子域(static.xxxx.com)提供简单转换。 四、缓存有效性 Invalidation 缓存减少了系统很大部分的多余请求。但是缓存终究只是真实数据（如数据库中的数据）的复制品，存在着和真实数据不一致的风险。 为解决缓存不一致性的问题，提出了缓存失效的概念： 4.1 直写缓存 Write-Through 该方案就是在写操作时，同时写入缓存和真实数据源（如数据库）。能保证快速的缓存检索，同时由于写的操作直接写入真实数据源，而具有缓存和存储保持完全的数据一致性。此外由于直接将数据推送给了真实数据源，最小化数据丢失的风险。 缺点： 写操作需要两次操作，因而存在高延迟。适用于频繁写和读的系统。 4.2 绕写缓存 Write-Around 该方案就是在写操作时，绕过缓存直接写入真实数据源。能避免缓存因为数据写入，而频繁更新。 缺点： 读操作会出现缓存丢失，因而需要重新到真实数据源检索，存在高延迟。 适用于不经常读取最近写入数据的系统。 4.3 回写缓存 Write-Back 该方案是在写操作时，只写入缓存就结束了。在一定条件(如一定的时间间隔)触发后，更新缓存到真实数据源。这对于写密集型应用程序，这将导致低延迟和高吞吐量 缺点：当节点处于故障时，将导致数据丢失。 适用于写密集行且数据不敏感的系统。 五、缓存淘汰原则 Eviction Policies 细节待更新 常见的几种缓存淘汰原则： FIFO (First In First Out) 先进先出，可以理解为一个队列。当要记录新的缓存，且缓存空间满了的时候，就淘汰缓存中存入时间最早的数据，即队列的头进尾出。 实现原理： Hash表 + 队列 LIFO (Last In First Out) 后进先出，可以理解为一个栈。当要记录新的缓存，且缓存空间满了的时候，就淘汰缓存中最新存入的数据，即栈的出栈入栈。 实现原理: Hash表 + 栈 LRU (Least Recently Used) 最近最久未使用，可以理解为一个队列，再加上刷新操作。当命中缓存时，就将缓存提出，重新压入队列。当记录新的缓存时，就淘汰最久没有用到的数据，即此时队伍的尾部。 实现原理： Hash表 + 双向链表 LFU (Least Frequently Used) 最近最少使用算法，顾名思义，就是淘汰缓存里面用的最少的数据。它根据数据的访问频次来进行淘汰数据，一个数据被访问过，把它的频次+1，发生淘汰的时候，把频次低的淘汰掉。 实现原理：Hash表 + 堆 其他算法 MRU (Most Recently Used)最近最多使用，同LRU相反，淘汰的时最经常用的缓存。适用于缓存越久没被使用，那下次被使用的概率就越高的场景。 RR (Random Replacement)随机替换，佛系算法，随机替换一个缓存。 六、Redis的实际应用 待Redis系列更新… >- 已阅留爪 (ฅ´ω`ฅ) - 下一章 《数据分区》-","link":"/xi-tong-she-ji/systemdesign-03-caching/"},{"title":"简单系统设计 —— 分布式系统（一）","text":"本系列，是自己学习Grokking the System Design过程中的笔记。希望读者在看完全文后，也能留下你们的经验。我万分荣幸能收到你们的消息。如果能从这里学到点东西，记得请我喝杯☕☕☕~ —— MinRam 一、前言 Overview 系统设计(System Design), 即针对系统的应用需求，设计出具有高性能，高拓展性，高可用性等的系统。 每个人学系统设计的目的不一样。笔者的学习目的只有两个： 社招面试准备。为通过微软面试的系统设计阶段做准备。 脱离底层工作内容（摆脱程序猿的帽子），挺进更具有技术价值的工作领域做准备。 实际工作中绝大多数内容都完全用不到算法，更多是增删查改(CRUD)、对接 API、调整数据格式之类的。更进一步的工作，通常也是和系统设计关系更大。 系统设计面试方面的准备资料，将在《程序员面试攻略》篇补充。 接下来，介绍些现系统中常见的核心模块。 个人对系统设计的理解，也只是冰山一角，并非立山顶，也只是站于山前，从前人留下的斑斑点点揣测大山全貌，其中个人猜想成分偏多，还望各位大师指点迷津。 二、分布式系统 Distubed Systems 分布式系统，即使用廉价、普通的机器集群，去完成单个机器无法完成的计算和存储任务。其根本目标就是利用更多的机器，处理更多的数据。 比如Google，Microsoft等大型系统，其背后都是由上万台设备组成的数据中心，但对于我们，只感知到他是一个系统。 从特征开始了解： 1.可伸缩性 Scalability可伸缩性是指当系统的任务（work）增加的时候，通过增加资源来应对任务增长的能力。可扩展性是任何分布式系统必备的特性。 举个例子，跑个算法程序，耗时很久。这时候我们有两种方式可以优化： 把原来的电脑换成性能更好的电脑。 ( 垂直扩容 Vertical Scaling) 把程序分成两半，分布在两个电脑上分别承担。 (水平扩展 Horizontal Scaling) 扩展性的目标是使得系统中的节点都在一个较为稳定的负载下工作，这就是负载均衡，当然，在动态增加节点的时候，需要进行任务（可能是计算，可能是数据存储）的迁移，以达到动态均衡。 其中 MongoDB 和 Apache Cassandra 就是典型水平扩容的分布式系统，可以通过增加机器节点，来提升对数据读写的处理能力。而MySQL则是垂直扩容的分布系统，提供了简单的途径用以切换到性能更好或者成本更廉价机器上，但这需要一定的停机时间（DownTime)。 伸缩不仅仅在资源的扩展，也包括在空闲时期对系统的缩容，来节省不必要的资源成本。特别是云时代，算力决定了产品的硬件成本, 淘宝不可能以双十一的处理成本来处理每日的订单。 2.可靠性 Reliability可靠性关注于系统发生故障(功能故障）的概率。例如当系统中有节点故障时，能被其他健康的节点替代（例如HA, 容灾等），那么可以认为在整体功能上有较高的可靠性。 以淘宝为例，当用户添加一个商品到购物车时候，系统应不丢失这个操作。即使负责处理这个操作的服务器死机，将由另一台服务器快速替代他处理这个操作。 显然冗余是保障系统的一个重要措施。这也同样带来了额外的成本，但对于宝贵的数据丢失，这点不足为道。 3.可用性 Available可用性关注于系统的所有生命周期里，提供服务的时间比例。 以飞机为例，一个月不间断飞行，那这架飞机的可用性较高。但如果停机维护，那就是不可用。 这里容易把可靠性和可用性的概念混淆： 可用性 被定义为系统的一个属性，它说明系统已准备好，马上就可以使用。换句话说，高度可用的系统在任何给定的时刻都能及时地工作。 可靠性 是指系统可以无故障地持续运行，是一个持续的状态。与可用性相反，可靠性是根据时间段而不是任何时刻来进行定义的。 如果系统在每小时崩溃1ms，那么它的可用性就超过99.9999%，但是它还是高度不可靠。与之类似，如果一个系统从来不崩溃，但是每年要停机两星期，那么它是高度可靠的，但是可用性只有96%。 补充： 平均故障间隔时间（MTBF，Mean Time Between Failure），是指相邻两次故障之间的平均工作&gt;时间，是衡量一个产品的可靠性指标。 平均修复时间（MTTR，Mean Time To Repair），是描述产品由故障状态转为工作状态时修理时间的平均值。在工程学中，MTTR是衡量产品维修性的值. 在维护合约里很常见，并以之作为服务收费的准则。 $$ Availability = \\frac{MTBF}{MTBF + MTTR} $$ 4.高吞吐 Effective 一个系统的高吞吐，指的是处理业务请求的效率，体现在两个方面： 响应时间 &amp; 吞吐量 响应时间，系统响应一个请求或输入需要花费的时间。 响应时间直接影响到用户体验，对于时延敏感的业务非常重要。 吞吐量，系统在一定时间内可以处理的任务数。这个指标可以非常直接地体现一个系统的性能，就好比在客户非常多的情况下，要评判一个银行柜台职员的办事效率，你可以统计一下他在 1 个小时内接待了多少客户。常见的吞吐量指标有 QPS（Queries Per Second）、TPS（Transactions Per Second）和 BPS（Bits Per Second）。 一个大型系统的操作业务是复杂繁琐的。以上两个指标只是粗略地估计系统的效率。除此之外，还有网络拓扑结构，网络负载和变化，涉及硬件还要考虑IO的读写等，要对一个大型系统建立性能模型，这依赖于对各方面性能指标的采集。 5.服务性 &amp; 可管理性 Serviceability or Manageability 该点考虑的是系统运行中，必经的修理和维护周期。 设计分布式系统时的一个重要考虑事项是操作和维护的容易程度。这决定了系统能保持可用时间的长短。 可管理，指在系统进行维护或者修复的简易程度和耗时长短。（如果系统不容易修复，那可以理解为系统将较长时间处于不可用状态） 考虑这点特性，需要关注与系统发生问题时： 能轻易找到问题根因， 快速提出问题修复方案 更新版本或者修复问题所需要的成本（停机？人力？物力？） 系统的操作所需要的技能程度 可管理性的考虑需要涉及到系统的整个生命周期（发布，更新等）。 题外话，服务性&amp;可管理性，在现在的大型系统中更侧重于运维的能力和成本。因此就有了Google提出的SRE团队的出现，专门针对整个系统的管理能力开发一系列监听和处理的模块。用来预测，监听和无人工干预的修复各种问题风险。在当下也有部分公司开始启动了更加创新的AIOps计划，结合智能领域，实现系统的智能管理。 综上的特征，最后根据自己产品特性需求，如搭积木般选择各式各样的组件，形成了如下的分布式系统（图中为典型组件，并非最佳组件选择）： >- 已阅留爪 (ฅ´ω`ฅ) - 下一章 《负载均衡的网关》-","link":"/xi-tong-she-ji/systemdesign-01-distubed-system/"},{"title":"瞎折腾系列 —— NPM技术雷达构建 （一）","text":"最近在梳理自己的技术栈内容，寻找一个比较清爽好看的形式来呈现和管理正好发现Thoughtworks的技术雷达，简洁，漂亮。那么把这个雷达搞成NPM包，移植入博客中，就是我的目的了。综上，开干😎。那么开始记录自己折腾路程。","link":"/xia-zhe-teng-xi-lie/programming-npm-technologyradar-01/"},{"title":"简单系统设计 —— 负载均衡（二）","text":"本系列，是自己学习Grokking the System Design过程中的笔记。希望读者在看完全文后，也能留下你们的经验。我万分荣幸能收到你们的消息。如果能从这里学到点东西，记得请我喝杯☕☕☕~ —— MinRam 一、前言 Overview 负载均衡, 指将流量分配到多个服务器，以确保流量能到合适的服务器进行处理。 负载均衡（Load Balance) 是分布式集群中的核心组件。分配流量到后端集群上的多个服务器中，主要目的是： 分摊： 将流量压力分摊到后端集群中的所有节点，这也是无状态水平扩容的基础要求之一。 可用： 将流量分配到可用的后端节点中，以保证对于前端使用者来说，服务一直是可用的。 安全: 能有效的分流压力攻击的流量，如DDOS. 环境隔离： 诸如协议转换（SSL流量的加解密）等一系列预处理，都会放在负载均衡上。 扩展概念：网关 Gateway, 架构上的概念，除了负载均衡外，直接分割了内部应用和外部服务，实现安全层的认证功能。解决服务治理的问题，将服务聚合的逻辑下沉到服务层。 二、在系统中的位置 Position在商用级系统中，负载均衡常放在以下三种会面对较大流量的位置： 终端（PC, 移动设备， 物联网设备) 和 Web服务器集群 Web服务器集群 和 内部服务集群（业务服务，缓存服务等） 数据库 和 数据库操作的服务 可以看出每个集群前，理论上都可以放入负载均衡作为入口和出口。需要权衡成本，维护等因素，最终决定是否需要。 三、优势 Benefits 用户体验优化： 用户体验不间断，更快速的服务。用户并不需要等待故障节点的修复。 单点故障隔离： 隔离单点故障对整个系统的影响，从而提供额外修复迭代的时间。 可用时间增加： 减少系统的停机时间，可以做到不停机的组件维护，版本升级（滚动升级，灰度发布）。 流量统计： 通过在负载均衡器部署额外的预处理组件，可以构建流量模型，为后续性能提升和业务优化，提供数据参考。 自动化入口： 对于商业级系统开发团队，自动化是解放团队人力的关键措施。作为流量必经站，负载均衡器是自动化运维的重要切入点。 网络管家： 允许系统组件灵活的网络，在不影响安全性，服务或性能的情况下能挑战更复杂的业务场景。实现软件定义网络。 四、转发策略 Algorithms 负载均衡是如何选择要发给哪台后端节点？ 对于负载均衡器，有两个重要的因素： 要发给谁 &amp; 能发给谁。前者是能处理流量的节点集合，后者是状态为健康的节点集合，两者的交集就是目标节点集合。那么剩下的就是以什么样的算法去将压力分布到目标节点集合上。 健康检查，是负载均衡器判断节点为健康的逻辑。基本思路：负载均衡器定期向后端节点发送健康检查请求，通过判断返回值来决定该节点是否为健康。如未收到返回值或者收到的返回内容中说明该节点无法接受流量，则负载均衡器将会把这个节点从目标节点集合移除，直到下一次检查或者节点主动告知。 面对不同场景，选择对应的转发策略： 最少连接 Least Connection Method 将流量转发给有效连接最少的服务器。适用于流量中有大量持久连接。 最短响应时间 Least Response Time Method 将流量转发给有效连接最少且平均响应时间最短的后端节点。 最少带宽 Least Bandwidth Method 将流量转发到处理流量最少的后端节点上。适用于大流量的业务场景。 轮询调度 Round Robin Method 将可用后端节点组成环状队列，依次转发给该队列。适用于持久连接较少且后端节点处理流量的能力一致的场景。 加权轮询调度 Weighted Round Robin Method 现实场景中，每个后端节点随着伸缩，处理流量的能力各不相同。因而加了一个参考的权值。权值高的后端节点，会比其他后端节点更早和更多地获取到流量。 IP哈希分散 IP Hash 通过客户端的IP地址决定哪个后端节点接受请求。 五、自身可用性单个负载均衡器仍存在故障的概率，因而可以设置冗余负载均衡器，构成主备HA或者集群形式。互相监听对方的健康状态。在主机故障的场景下，备用机能主动接管流量。 六、负载均衡的类型（加深内容） 在七层开放系系统互连模型（OSI)中， 网络防火墙 位于1-3层（L1-物理连线，L2-数据链路，L3-网络层）。而负载均衡器,则在4-7层（L4-传输层，L5-会话层, L6-表示层，L7-应用层)。 L4 根据来自网络和传输层协议的数据（IP地址和端口）完成转发 L7 读取数据包内容，可以根据HTTP Header，Uniform resource identifer，HTML form data和SSL Session ID的内容决定转发逻辑。 根据负载均衡的协议逻辑，主要分为一下几种类型： 6.1 SDN使用SDN（软件定义网络）的负载平衡将控制平面与数据平面分离以进行应用交付。这允许控制多个负载平衡。 该类型的负载均衡器，笔者也是一知半解，目前只看到相关的学术论文，待后续补充。 6.2 UDP针对UDP协议进行转发的负载均衡器，仅保留基础的纠错，追求极致的性能&amp;延迟。特别适用于游戏和直播的产品中。 6.3 TCP常见的业务负载均衡器基本是采用TCP协议。大部分的软件系统还是提供数据处理服务，光丢包就会丢失重要的数据。需要基于TCP协议保障数据包准确无误地到达目的地。 6.4 SLB服务器负载均衡器，针对后端节点为服务器的使用场景，将客户端流量分配到服务器上，以确保一致的高性能业务交付。 6.5 Virutal虚拟化负载均衡器，指负载均衡器的承载体是虚拟化设备（如虚拟机）。常见于正在尝试云化的产品。仍存在传统硬件的限制（维护，停机，可扩展性） 6.6 Elastic弹性负载均衡器，在需要的时候拓展自身实例，以满足业务需求。如流量增大，或者后端节点增加，需要提升负载均衡器的流量处理能力和后端节点的管理能力。 6.7 Geographic地理负载均衡器，可以根据需要将流量转发到指定地理位置的后端节点，或次级负载均衡器。在全球级商业系统，往往会有一个全球负载均衡器，来处理来自世界各地的流量，再交给离流量发送者较近的次级负载均衡器，以减少延迟。、 6.8 Multi-site多站点负载均衡器，用来在多个站点间分配流量。如上一点提到全球负载均衡器。常见使用场景，如在生产和容灾站点间分配流量，以保证整个系统的可用性。 6.9 LBaaS在云时代，负载均衡器被抽象成一种云服务类型。不再局限于某个服务器上，能更好地配合云计算的使用场景。大部分是指基于OpenStack虚拟架构的负载均衡器。 除了从功能的分类，负载均衡器还有硬件和软件的区分。 >- 已阅留爪 (ฅ´ω`ฅ) - 下一章 《缓存》-","link":"/xi-tong-she-ji/systemdesign-02-load-balance/"},{"title":"简单系统设计 —— 索引（五）","text":"本系列，是自己学习Grokking the System Design过程中的笔记。希望读者在看完全文后，也能留下你们的经验。我万分荣幸能收到你们的消息。如果能从这里学到点东西，记得请我喝杯☕☕☕~ —— MinRam 一、前言 Overview 当数据量达到一定的规模，数据库的查询性能会明显下降。这时候就是索引的出场。 数据库索引 Index就是为了提高数据库访问数据的速度（即查询的速度 Select/Update/Delete）。它的实现原理在主流数据库中时平衡树（Balance Tree &amp; B+ Tree)。也有部分数据库采用的是哈希桶的结构。 通过记录关键属性的值，在符合条件的查询操作时，就不再需要进行数据库的全表扫描，只需要扫描较少的索引页和数据页。 二、例子 Example 图书馆，一直都是关系数据库的好例子。（😗我绝不是偷懒不去想） 图书馆中收藏书籍的清单，可以看作是数据库的一张表，通常包含了这几个属性：书名，作者，刊号，主题和出版日期。通常在图书馆，有几种经常用到的查询方式：书名检索，作者检索和刊号检索。这样我们就可以通过，书名，作者或者刊号，来轻易查询到一本书或一系列书。 这里的书名，作者和刊号就像图书馆的索引。它们提供一个清晰的数据列表，便于检索。所以索引其实可以理解为一个目录，指向了数据的实际位置。当我们创建索引的时候，我们会存储该列的值，以及指向实际行数据的指针。 可以发现，索引往往是我们经常检索用到的列属性。 我们把经常操作的数据成为有效负载。 对于TB大小级别的数据库，并不是所有数据都是活跃的，例如我们只会在被查水表了，才会去翻看n天前的聊天记录。因而数据库中有效负载数据，往往是索引的第一选择。 三、代价 Cost 既然索引这么好用，那为啥不暴力把表的所有列全建成索引？ 如果把整个表都建成索引，那就跟全表扫描一样的结果了（和二叉树退化成链表同理）。同时，索引的存在会显著加快数据检索，也会减少数据的更新操作（Insert/Update)。具体在于，我们插入一条新数据时，需要更新索引。我们更新到索引关键属性的值时，也同样需要索引。 因此，我们应避免不必要的索引，并即使删除无效的索引。 索引终究只是用于数据的检索动作。如果有个数据库，经常写入数据，但检索的动作占很小的比例，那就没必要再添加索引了。真没必要脱裤子放屁👻 四、类型 Type （拓展知识）索引的类型分为一下几种： 4.1 聚合索引 聚合索引 又叫为主键索引，值得就是一张表中的唯一主键。 在现有数据库中，如果建表不指定主键，数据库会拒绝创建表的动作。实际上，一个表如果没有主键，那么他就只能被无序存放，行之间无任何关联，在通过主键检索时，也只能遍历整表。相反的，当我们指定主键后，整个表就变成了索引，从一行行数据，变成了平衡树的结构。（这里不拓展平衡树原理） 1SELECT * FROM student WHERE student_id = 88888; 每个表只有一个聚合索引。聚合索引是通往实际数据的唯一路径。 4.2 非聚合索引 非聚合索引，就是给非主键的属性，加上索引。 非聚集索引和聚集索引一样， 同样是采用平衡树作为索引的数据结构。索引树结构中各节点的值来自于表中的索引字段， 假如给user表的name字段加上索引 ， 那么索引就是由name字段中的值构成，在数据改变时， DBMS需要一直维护索引结构的正确性。如果给表中多个字段加上索引 ， 那么就会出现多个独立的索引结构，每个索引（非聚集索引）互相之间不存在关联。 12KEY 'idx_name' ('name')SELECT * FROM student WHERE name = 'MinRam'; 每创建新的索引，该字段的数据会被单独拷贝出来。即给表添加索引，会导致表的大小增加，占用存储空间。 非聚合索引是先通过索引查到主键，再通过主键查到数据。 4.3 联合索引 联合索引， 就是将多个字段联合在一起，构成一个索引。 联合索引，一个重要的用处就是避免回表，其中回表指使用非聚簇索引进行查找数据时，需要根据主键值去聚簇索引中再查找一遍完整的记录。 12KEY 'idx_name_sex' ('name', 'sex')SELECT student_id, name, sex FROM student WHERE name = 'MinRam' AND sex = 'male'; >- 已阅留爪 (ฅ´ω`ฅ) - 下一章 《代理》-","link":"/xi-tong-she-ji/systemdesign-05-index/"},{"title":"简单系统设计 —— 数据分区（四）","text":"本系列，是自己学习Grokking the System Design过程中的笔记。希望读者在看完全文后，也能留下你们的经验。我万分荣幸能收到你们的消息。如果能从这里学到点东西，记得请我喝杯☕☕☕~ —— MinRam 一、前言 Overview 分布式系统往往需要处理大量的数据集，如同双十一，电商需要处理上亿级别的订单量，而这些数据如果塞到一台单机数据库上，那他能否处理，以及性能有多差，可想而知。 数据分区 就是将大数据库（DB)分解为许多较小节点的技术。对于一个大规模数据集，通过分割一个DB/表的手段，让多台机器联动处理。从而提高系统的管理能力、性能、可用性以及适当的负载平衡能力。 还有一个关键因素： 当面对DB性能瓶颈时，通过添加更多的机器来水平扩容，往往比更替更强大的服务器垂直扩容来说，更便宜也更可行。 单机数据库的瓶颈： 单个表数据量越大，读写锁和插入操作重新建立索引效率越低。 单个库数据量太大（一个数据库数据量到1T-2T就是极限） 单个数据库服务器压力过大，具体指IO延迟和cpu占用率 读写速度遇到瓶颈（并发量几百） 二、分区方式 Partition Method化整为零的几个主要方式： 2.1 水平分区 Horizontal partig这种分区形式是对表的行进行分区，通过对某个属性（列）进行分割，得到多个分组，分布在不同的机器上。但整体表的特性仍然存在。这种分区的的关键问题，在于如果分区方式不合理，会导致各分区比重不均匀，导致各个节点的压力不一致。 举个例子：对于淘宝上一年的订单数据，根据每个月份可以分成12个分区。但我们知道11月份的订单数据往往最多。 2.2 垂直分区 Vertical这种分区形式是对表的列进行分区，将不同的表或者是将表的列拆成多个小表，帆布在不同的机器上。这种分区的关键问题，在于随着应用的体量的增长，需要面临进一步的分区。 举个例子： 对于用户表（头像，关注列表，昵称），拆分成个人信息表（头像，昵称），关注表（关注列表）。但随着用户体量的增加，单个服务器仍要面临瓶颈（一个服务器是不可能处理1.4亿用户的元数据查询） 2.3 基于字典的分区 Dictionary Base以上两种方式都有自己缺陷，因而在实际系统中，经常采用一种松散耦合的方式：抽象数据查找层。即在应用系统到数据元数据间，新增一层机制，单独实现元数据到DB服务器的映射关系。其目的就是能够在不影响应用程序的情况下执行DB池添加节点或者更改分区方案。 分区，狭义上指的就是将一个表的数据分成N个区块，在逻辑上仍为一张表，但底层由N个物理块组成 分表，就是把一张表按一定的规则分解成N个具有独立存储空间的实体表。系统读写时需要根据定义好的规则得到对应的字表明，然后操作它。 分库，分表后数据库中的表会增加，进而需要拆分过于庞大的数据库。 将数据库比作图书馆整个分类，一张表就是一本书。当要在庞大的图书馆找到一本书显然不容易，但若将书籍分成多个类别，就可以通过类别快速找到某个书。 三、划区的依据 Partitioning Criteria本划区依据，特指水平分区。 3.1 基于键值或哈希的分区 Key or Hash该方案，就是通过一个哈希Hash函数来映射我们的实体数据的一些属性，生产对应的分区号。例如，我们由N个节点，那么可以通过ID mod N来决定存储的服务器编号。 缺陷：当我们服务器节点增加时，就会更改哈希函数的关系，这需要成功新分配数据和服务停机。但我们可以通过一致性哈希解决问题。详见后续章节。 3.2 列表分区 List该方案，就是有个列表，决定对应值的记录放在哪个服务器。例如北欧地区的国家为一个分区，亚太地区的国家为一个分区。 3.3 轮询分区 Round-robin该方案，就是雨露均沾，对于N个分区，编号为I的元数据将被分配到 ‘I mod N’的分区上。 3.4 复杂分区 Composite数据往往是复杂多样的，小孩子才做选择，实际系统中会结合以上分区方式，提供多层的分区依据。 四、分区的常见问题Common Problems相比于单点数据库，分区数据库因为实际执行服务器将是个集群，因而会有一些额外的约束条件和额外的执行复杂度： 4.1 连接表 &amp; 反规范化 连接 Join，简单来说就是连接多个表，从而查到所需要的数据。 规范化 Normalization, 就是将表尽可能地拆开，减少数据的冗余。具体可以搜索下数据库的关系范式理论。 在单点服务器中执行连接并没有什么困难，但是一旦数据库由单点转成多个节点后，跨分区的连接通常不可行或性能不高效。解决这个问题的方式就是进行适当冗余的反规范化，让操作只在单表中执行。当然这也带来了新的挑战 - 冗余数据需要保持一致。 4.2 参考完整性 Referential integrity 关系数据库，最常见的两种约束 唯一键约束 和 完整性约束。 参照完整性，简单来说就是，两个数据表是有关联的，父表中的记录必须存在，子表的记录才能存在。显然在分区数据库中强制执行数据完整性约束(比如外键)可能非常困难。 大多数RDBMS不支持跨数据库服务器上的外键约束。 当我们需要这个约束时，就需要应用程序必须在代码中强制执行参照完整性。 在这种情况下，应用程序通常必须运行常规SQL作业来清除悬空引用。 4.3 重新分配 Re-Balance尽管我们在分区方案设计的很完美，随着系统的数据规模增加，我们都需要面对重新分配分区。 按照分区规则，某个分区上的数据超过了承载量。 例如，大量国内用户注册，导致亚太区数据分区存储较大比例的数据 某个分区上存在较多的负载。 例如，随着用户体量增加，头像的请求明显增加。 面对这种情况，我们要么构建更多的数据分区，要么重新平衡各分区的数据比例。这就代表我们需要挪动数据前往新的位置，在这过程中要实现不停机是一个很大的挑战。当然，使用字典分区的方式，抽象数据查找层，能有效的实现零停机（Zero-Downtime)的效果，但也暴露了查找层存在故障的可能（单点故障）。 五 其他 Others分布式数据库是一个很庞大的技术体系，本章只是简单系统设计，重心在于入门。笔者会在后续系统学习数据库后，重新润笔。 对于分布式数据库如果很感兴趣，可以进一步看看 Google Spanner的设计论文。 Spanner 是谷歌公司研发的、可扩展的、多版本、全球分布式、同步复制数据库。它是第一个把数据分布在全球范围内的系统，而且支持外部一致性的分布式事务。 >- 已阅留爪 (ฅ´ω`ฅ) - 下一章 《索引》-","link":"/xi-tong-she-ji/systemdesign-04-data-partition/"},{"title":"简单系统设计 —— 代理（六）","text":"本系列，是自己学习Grokking the System Design过程中的笔记。希望读者在看完全文后，也能留下你们的经验。我万分荣幸能收到你们的消息。如果能从这里学到点东西，记得请我喝杯☕☕☕~ —— MinRam 一、前言 Overview 前面提过负载均衡, 会将前端的流量按规则分发给后端服务集群，以此来分摊压力。而代理就是其中的一个能力。 代理服务器，是客户端和后端服务器的中间服务器。特别是WEB类型的后端服务器。客户端通过连接代理服务器，请求对应的资源（HTML,CSS,Connect等）服务。它可以是软件形式（如Nginx)又或者是硬件形式(因价格昂贵，比较罕见)。 简单讲，代理就是我们不直接去做一件事而是让另外一个人代替我们去做一件事。通常，代理用于过滤请求、记录请求，或者有时转换请求（通过添加/删除头、加密/解密或压缩资源）。 除此之外，代理还能做到： 缓存网页，来提高响应性能 负载均衡 作为一个前端，控制和保护某个服务的网络请求 隐藏用户身份（如VPN😗） 负载均衡器 和 代理服务器 在整体系统中的位置一致，往往整合成网关模块。前者侧重于分摊压力，后者侧重于屏蔽客户端对服务的感知。可以理解为，负载均衡是依靠代理实现的。 二、类型 Types代理层，主体是放在客户端和业务服务器之间，所以它可以在客户端上，也可以在业务服务前新增服务器等。而常见的几种类型： 1. 正向代理 Foward Proxy大多时候说的代理服务器，指的是正向代理。一个面向内网的代理其中客户的客户端或组提供服务。通常，这些客户端是内网的一部分。 以www.example.com的服务器为例，从客户端发起请求开始： 内网客户端尝试连接到代理服务器，请求访问www.example.com; 请求通过内网到达代理服务器; 代理服务器根据之前设置的策略，选择通过，或者拒绝; 允许: 将请求转发到对应的Web服务器，将结果返回给代理服务器，再响应之前的请求。 拒绝: 根据策略返回响应内容； 正向代理是权限和控制的关键点，并且容易插入访问安全策略。 企业、组织、学校使用正向代理，以屏蔽内网中的客户端访问Internet的重要内容。主要考虑的过滤方式：例如URL，DNS黑名单，URL正则表达式过滤，MIME过滤或内容关键字过滤。 内网中的缓存服务器。如果一个资源被下载了很多次，那么代理可以将内容缓存在服务器上，这样下次另一个客户端下载相同的内容时，代理会将之前存储在服务器上的内容发送给客户端。 一些常见的正向代理软件（基于服务器的）： Cgi-Proxy Glype Squid …只要理解组件的使用场景和实现原理，就能快速了解该类型的软件。在大厂中往往有自己一套的代理软件。 2. 反向代理 Reverse Proxy 反向代理的作用与正向代理的作用完全相反。针对客户端的正向代理代理，针对服务器的反向代理代理。 反向代理通常是一个面向系统内部的代理，作用在请求流的前端来控制和保护对系统内部网络上服务器的访问。 来自 Internet 并以系统为目的地的所有流量都将通过代理服务器。在客户端看来，系统只是一个门。反向代理服务器代替其后端服务器，接受来自外部客户端的请求，并将请求转发到一台或多台后端服务器以处理请求。客户端接收到来自代理服务器的响应中，并不会有任何原始服务器的信息。 以www.example.com的服务器为例，从客户端发起请求开始： 客户端向系统发起请求； 请求通过Internet到达代理服务器; 代理服务器根据之前设置的策略，选择通过，或者拒绝; 允许: 将请求转发到对应的Web服务器，将结果返回给代理服务器，再响应之前的请求。 拒绝: 根据策略返回响应内容； 正向代理隐藏客户端的身份，而反向代理隐藏服务器的身份。 反向代理用于以下目的： SSL加速：创建安全网站时（如协议为https)，安全套接字层 (SSL) 加密通常不是由 Web 服务器本身完成，而是由配备 SSL 加速硬件的反向代理完成。反向代理为任意数量的主机提供 SSL 加密，无需为每个主机提供单独的 SSL 服务器证书； 负载平衡： 反向代理可以将负载分配到多个后端服务器； 缓存静态内容：反向代理可以通过缓存静态内容（如图片，静态HTML等）来分担Web服务器的压力。详见缓存篇 压缩：代理服务器可以优化和压缩内容以加快加载时间。 安全性：代理服务器是额外的防御层，可以防止某些操作系统和 Web服务器特定的攻击 常见的HTTP反向代理软件（服务端）： Apache mod_proxy（也可以作为 HTTP 的正向代理） Nginx HA-Proxy Varnish Cache 三、尾言 系统设计中各功能的实现，都有相对应的基础算法，在社招面试中常伴随着一起考察。 >- 已阅留爪 (ฅ´ω`ฅ) - 下一章《一致性哈希》-","link":"/xi-tong-she-ji/systemdesign-06-proxy/"},{"title":"简单系统设计 —— 一致性哈希（七）","text":"本系列，是自己学习Grokking the System Design过程中的笔记。希望读者在看完全文后，也能留下你们的经验。我万分荣幸能收到你们的消息。如果能从这里学到点东西，记得请我喝杯☕☕☕~ —— MinRam 一、前言 Overview 《Consistent Hashing and Random Trees: Distributed Caching Protocols for Releifying Hot Spots on the World Wide Web》一文中完整介绍了一致性哈希的思想，有兴趣可以深挖下。 一致性哈希 （Consistent Hash）, 是分布式系统中极为重要的一个组成。首先了解什么是哈希表，总的来说就是这样一个公式： $$ Index = Hash_Function(Key) $$ 包含：键，值和哈希关系(给定键能得到唯一的值或者存储值的地址)。能够在恒定时间内通过键，找到对应的值。 前面提到的，当我们存在容量为N的缓存机制时，或者总结点数为N的数据分片节点。最直接且常见的哈希方程就是 Key % N。但将面临两个问题： 不支持水平扩展 Not be horizontally scalable 当插入一个新的缓存节点时，整个哈希表中的映射关系将被破坏失效[ K mod N ≠ K mod (N+1)]。这将导致系统需要较长的停机时间，去更新所有的缓存映射。 分布不均匀 Not be load balance 实际场景中，数据并不是均匀的。有些数据更经常被访问（Hot data)，并且更容易被哈希到同一个节点；而相反的，有些数据几乎用不到； 而这些问题，能够被一致性哈希很好地改善。 二、一致哈希 Consistent Hash 对于分布式缓存系统或者类似的分布式哈希表（Distributed Hash Table), 一致哈希策略至关重要。 上节中，传统的哈希函数，将Key与当前节点数N关联。导致增删节点时候，需要重置所有的映射关系。而一致性哈希的目的，就是使增删节点时需要重置键值数量最小化。 在一致哈希中，整个哈希函数与节点数量N，并无直接关系： 当节点添加时，其他节点（部分节点）上承载的部分键值对，将被重新分配到该新增节点上； 当节点移除时，该节点上承载的部分键值对，将被其他节点分摊； 三、策略原理 How to work 一致性哈希函数，常把键映射成一个整数。例如将输入Key映射到[0,256]的输出范围内。从而整个输出范围，通过头尾相接，可以形成一个环。 主要举例说明： 给定一个缓存服务器列表 [A, B, C], 每个输入都会被映射到环上的某个值 [0, 256]。 将缓存服务器映射到环上的某个点 对于每个环上的值，按照顺时针🔃方向移动，碰到的第一个服务器就是对应缓存所在的服务器。 通过以下动画演示： .CanvasAnimationViewer { border: 1px solid rgb(210, 210, 214); border-radius: 4px; margin-bottom: 10px; } #svg2_line2,#svg2_line1,#svg3_line1,#svg3_line2,#svg4_line1,#svg4_line2{ stroke-dasharray: 450; stroke-dashoffset: 450; animation: draw 2s linear forwards; } #svg3_nodeA{ animation: disapear 0.8s linear forwards; } @keyframes disapear{ from { opacity: 1; } to { opacity: 0; } } @keyframes draw { to { stroke-dashoffset: 0; } } .index { font-size: 12px; text-align: right; margin-right: 15px; margin-bottom: 10px; } .button-box { display: flex; -webkit-box-align: center; align-items: center; -webkit-box-pack: center; justify-content: center; margin-top: 15px; } .CanvasAnimationViewer .index { margin-bottom: 10px; } .circle-button { font-size: 14px; font-weight: 700; text-align: center; transition: all 0.2s ease 0s; cursor: pointer; display: flex; -webkit-box-align: center; align-items: center; -webkit-box-pack: center; justify-content: center; padding: 9px; border: none; border-radius: 100%; background: rgb(255, 255, 255); color: rgb(143, 143, 153); margin-right: 18px; box-shadow: rgb(0 0 0 / 20%) 0px 0px 9px; } .circle-button:disabled { cursor: not-allowed; background: rgb(245, 245, 245); } .circle-button:hover:not([disabled]) { color: rgb(255, 255, 255); background: rgb(85, 83, 255); box-shadow: rgb(0 0 0 / 20%) 0px 0px 15px } 0 of 0 var index = 1; var imageList = [ 'Layer 12560Output Range: [0, 256]', 'Layer 12560Current Status: 3 Nodes &amp; several valuesNode CNode ANode B', 'Layer 12560Current Status: Remove Node ANode ANode BNode C', 'Layer 12560Current Status: Add Node, Remap valuesNode CNode ANode B']; var animateList = []; var indexElement = document.getElementById('indexPage'); var sumElement = document.getElementById('sumPage'); var preButton = document.getElementById('CanvasAnimator-PreBtn'); var nextButton = document.getElementById('CanvasAnimator-NextBtn'); var resetBUtton = document.getElementById('CanvasAnimator-ResetBtn'); var imageBoard = document.getElementById('images-board'); function animate1() { } function animate2() { } function load_images() { animateList.push(animate1); animateList.push(animate2); } function _init(){ load_images(); blender(); } function blender() { indexElement.innerText = index; sumElement.innerText = imageList.length; if (index = imageList.length) { nextButton.setAttribute(\"disabled\", \"disabled\"); } else { nextButton.removeAttribute(\"disabled\"); } /* start blender canvas */ imageBoard.innerHTML=imageList[index-1]; if (index new Promise((resolve) => setTimeout(resolve, delay)) async function CanvasAnimator_PlayHandler(event) { autoFlag = true; for (;index < imageList.length;) { if (autoFlag == false) break; await sleep(2000); ++index; blender(); } } function CanvasAnimator_ResetHandler(event) { autoFlag = false; index = 1; blender(); } _init() // Injection for buttons. document.getElementById(\"CanvasAnimator-PreBtn\").onclick = CanvasAnimator_PreHandler document.getElementById(\"CanvasAnimator-NextBtn\").onclick = CanvasAnimator_NextHandler document.getElementById(\"CanvasAnimator-PlayBtn\").onclick = CanvasAnimator_PlayHandler document.getElementById(\"CanvasAnimator-ResetBtn\").onclick = CanvasAnimator_ResetHandler 每个键Key, 通过哈希函数，映射到[0, 256]之间，再通过顺时针，找到自己的命中节点（缓存节点）； 当移除缓存节点时，比如节点A，所有在节点A上的键Key，都会重新映射到下一个顺时针节点上，而其他节点不会受到影响； 当添加一个缓存节点时，比如节点A，将从下一个顺时针节点中，移动部分键Key到新增节点上； 上面提到实际数据虽然是随机分布的，但并非均匀分布。这会导致最终映射到环上的值也不均匀。因而提出了数据副本的概念。对于一个键Key，数据会被存储在多个缓存节点中，存在多个副本。随着副本数量增加，最后在环上的分布将更加均匀。 >- 已阅留爪 (ฅ´ω`ฅ) - 下一章《CAP》-","link":"/xi-tong-she-ji/systemdesign-07-consistenthashing/"},{"title":"简单系统设计 —— 面试（结）","text":"一、前言 Overview 简单系统设计, 共9篇，边学边写。在努力克服自己的惰性，终于能在2022年来临前完成系列。在整个过程中，遇到新的思想，新的问题，留着后面解开。 系列开篇的时候，学习系统设计的主要目的（面试），所以在总结篇，就整理下自己对系统设计整体知识点和面试思路。希望N年后，自己回头看的时候，能读出自己的幼稚与不足。 如果整个系列有帮助，记得请我☕~ 二、系统设计面试的目的 DestinationIT公司中，都在构建和优化商业级系统（可拓展 &amp; 高性能）。所以我认为，公司更需要具备合理设计技能的员工（工程师≠码猿）。 系统设计面试，是一道开放性题目。除了设计能力，还有对思考过程、算法知识、人与人沟通以及突发思维的考量。脑子要转得快，要灵光，要系统，要谨慎。这才配得上工程师的称号。 三、关键步骤 Steps1. 澄清需求和问题 Rome was not built in a day. 不管是淘宝，支付宝还是微信，他们所包含的上千个功能，都不是在短短45~60分钟设计完成的。这是多年的功能迭代，实践后累积的。 对于我们，时间有限，我们只能把面试官的题目，缩小到关键功能上。需求可以分成功能性需求和非功能性需求。然后开始在白板设计简单功能。 例如： 在设计一套打车系统，可以列下如下要求： 乘客可以预定和取消行程 系统必须匹配司机 司机可以取消行程 乘客和司机可以互相评分 支持支付渠道 乘客可以查看司机的实时定位 提出要求，是为后续的设计范围。同时需要对面试官提出明确的问题（提出一个好问题是一门学问，同时能展示自己的逻辑思维）。比如用户群体是什么样的？系统后续是在什么平台被使用的？这些都将协助自己识别，自己设计瓶颈和预留拓展性。 2. 容量估算在明确系统设计需求后，下一步就是需要确定系统的受众。了解系统的用户量级，如果未给出，应主动询问面试官。这是一个极其重要的设计参考值，能帮助我们对系统设计瓶颈的预估。 通过活跃用户的预测，进而估算系统接受请求的量级，以及预估所需存储的数据空间。同时需要知道系统的请求重心是在读还是写，预估读请求和写请求的比例和量级，从而决定使用SQL或者NoSQL的数据库，以及缓存的迫切程度。 同样举例说明： 假设我们要设计一款类似Weibo的系统。在这种情况下，我们可以做出假设性估算： 3亿活跃用户，每天发文6亿。 热数据占20%。 每个用户平均有1000关注量。 一条发文至少被转发1000次。 每条发文上至少带有一个额外的媒体资源（图片或者视频）。 从而我们可以估算出这个读写请求的量级，所需服务器的规格和数量。同时能估算出1年所需要的数据存储大小（发文大小 x 每日发文量 x 天数） 。 这些同时也是系统发布前，性能测试的标准~ 3. 设计目标系统设计的的部分主要要求：延迟 &amp; 吞吐量。 延迟 是指处理客户端的请求，并返回结果所需要的时间； 吞吐量 是指在给定时间间隔内可以处理的请求数； 高性能系统，必须具有最小延迟和最大吞吐量。设计京东网站，如果加载时间很长，那客户早就跑光了。如果双11节日，网站就容易因此崩溃，然后因此亏本，老板跑路。 第二个设计目标是在可用性和一致性之间进行选择。根据CAP理论，可以使用 CP 或 AP 系统来容忍网络中的故障。可用性和一致性的选择由系统类型决定。 如果是金融项目，则会更注重一致性。然而，对于微博这类的系统，则更注重于可用性。 4. API定义 &amp; 架构确定完需求后，就需要完善后端系统暴露的API。设计请求参数，响应体，状态码，以及HTTP方法类型等。API设计是否使用REST、GraphQL或GRPC。 设计好API接口后，开始在白板中绘制系统所需要的组件。从客户端的组件开始，到API网关、负载均衡策略。 如果你被要求设计一个像爱奇艺平台时，你还可以谈论 CDN（内容交付网络），它有助于提供静态图像或视频文件。 对于每个API接口，对于非CRUD的API接口，还需要考虑是否需要补充高级算法。例如，设计电商平台中： 要获得首页商品列表，可以提出一个商品推荐算法。 如果用户查看商品详情，这将是一个普通的 CRUD API接口。 5. 数据库 &amp; 缓存对于大部分系统，数据库是必不可少的组件。针对于系统的长期存储数据： 应该清楚地了解数据建模中涉及的实体及其之间的关系。 弄清楚数据是结构化的还是非结构化的，以及它是否需要架构灵活性。上述问题的答案将影响，系统选择使用 SQL 还是 NoSQL 数据库。 大多数系统都是重读系统。因此可以通过根据访问模式在列或一组列上创建索引来加速所有数据库读取查询。可以使用一个主从数据库的架构，在主设备上执行写入，而从从设备上完成读取。这会将读取与写入隔离开来，从而提高系统的性能。 从数据库读取会导致 IO 操作在计算上执行起来很昂贵。系统可以在应用程序和数据库之间添加一个缓存层以最小化磁盘 IO。这将进一步提高系统的性能。在添加缓存时，需要在缓存逐出策略以及缓存模式（例如直写、回写、缓存搁置等）之间进行选择 当系统是面对百万级用户时，单节点数据库不再承受其并发量，需要采用分布式数据库。因此需要在多个数据库服务器之间分发数据，这称为数据分区。面试官可能会询问有关可用于分发数据的不同数据分区策略并讨论使用每种策略的权衡。 四、总结 Summary不足的地方还是很多，很多地方总是泛泛而谈，很多地方理解的不够透彻，很多地方自己讲解的不够透彻。路还很远，继续走下去了~ >- 系统设计完结撒花❀ -","link":"/xi-tong-she-ji/systemdesign-09-interview/"},{"title":"简单系统设计 —— CAP理论（八）","text":"本系列，是自己学习Grokking the System Design过程中的笔记。希望读者在看完全文后，也能留下你们的经验。我万分荣幸能收到你们的消息。如果能从这里学到点东西，记得请我喝杯☕☕☕~ —— MinRam 一、前言 Overview CAP理论，也叫Brewer理论，最早由Eric Brewer在2000年的the Principles of Distributed Computing会议上发表的Towards Robust Distributed Systems，并在两年后由麻省理工学院分布式系统研究人员 Seth Gilbert 和 Nancy Lynch 教授，在Brewer’s conjecture and the feasibility of consistent, available, partition-tolerant web services中证明了猜想。 CAP理论，是针对于分布式系统（共享数据的互联节点集群中，其节点应为有状态的），我们只能在系统的写/读对中获得三个保证（一致性、可用性和分区容错）中选择两个。总会有一个特性无法被保证。 CAP理论， 可以认为是分布式系统设计的统一纲领之一。而统一纲领，就类似一种约定，解决了分布式系统中不同模块、不同开发人员，在公共层面上能有一系列原则来指导设计，避免一些设计冲突。 比如，在分布式系统中，服务依赖问题，每个服务都是由各自的开发人员开发，导致处理策略也将不同： A服务，在请求服务失败后，处理策略是不断重试； B服务，在请求服务失败后，处理策略是记录错误，不再尝试连接；当AB之间的网络出现问题，导致服务请求失败时，就会有各自的处理方式，进一步可能导致业务失败，这就会造成模块方面的不可用。 二、理论内容 ThreoremCAP理论，说明一个分布式系统中不能同时满足三种特性。 1. C: 数据一致性 Consistency 数据一致性，要求的就是数据能保持整齐一致，能一致地变化。 数据是哪来的？ 前面提到，CAP理论针对的是有状态且共享数据的互联节点集群，数据自然是指节点中存储的数据。在实际分布式系统中，除了分布式数据库外，每个服务集群都会存储有状态的数据。 数据何时会变化？ 既然要求数据保持一致，那么保证变化一致，就可以达到这样的目的。那么加上对象，仅当存储共享数据的服务节点，收到数据更新请求（增删改）后，数据才会变化 如何确定数据是一致性的？ 数据只有被用到才能确定是一致的，也就是读操作。 数据一致性的判断就是在一次写入操作后，通过读操作，能获取到各个节点的共享数据，且数据应是一致的且是变换后的数据。 但是系统不是永远都是正常运行的！如果系统内部发生了问题，导致部分节点无法更新变化。这时候，就意味着想看到最新数据的读请求们，很可能会得到旧数据（不同版本的数据）。此时，为了保证分布式系统对外的数据一致性，于是选择不返回任何数据。 这个时期，系统是处于不可用状态下的。 CAP 定理是在某种状态下的选择，跟实际工程的理论是有差别的。上面描述的一致性和 ACID 事务中的一致性是两回事。事务中的一致性包含了实际工程对状态的后续处理。但是 CAP 定理并不涉及到状态的后续处理，对于这些问题，后续有 BASE 理论等工程结论去处理。 稍微实践系统下的一致性: 一致性的强弱实际系统中，往往会选择中庸的答案，会根据业务场景选择对应的强度的一致性要求。 弱一致性：在写入之后，访问可能看到，也可能看不到（新数据）。只是尽力优化之让其能访问最新数据。这种方式可以 memcached 等系统中看到。弱一致性在 VoIP，视频聊天和实时多人游戏等真实用例中表现不错。打个比方，如果你在通话中丢失信号几秒钟时间，当重新连接时你是听不到这几秒钟所说的话的。 最终一致性： 在写入后，访问最终能看到写入数据（通常在数毫秒内）。数据被异步复制。 DNS 和 email 等系统使用的是此种方式。最终一致性在高可用性系统中效果不错。 强一致性：在写入后，访问立即可见。数据被同步复制。文件系统和关系型数据库（RDBMS）中使用的是此种方式。强一致性在需要记录数据的系统中运作良好。 2. A: 可用性 Availability 系统所能体现的价值，就是操作。 可用性，在 CAP 里就是对操作结果的要求。它要求系统内的节点们接收到了无论是写请求还是读请求，都要能处理并给回响应结果。 同时还应满足三个常见的要求： 既然是请求，就会有返回延迟，可用性对请求到拿到结果的耗时应在合理范围内（由业务定义）。 如果节点能正常接收请求，那么就一定需要返回结果，不应忽略客户端的请求，即便数据是错误的或者并非最新的。 如果节点不能正常接收请求，那么一定由其他平级节点能够代替处理请求。 3. P: 分区容忍性 Partition Tolerance 网络是不可靠的 分布式系统中，各个节点之间是通过网络连接的，而网络是不可靠的（延迟，丢包，断连）。当网络出现问题时候，系统中就会出现不同数据版本的分区，当然也有其他原因（如网卡故障，节点超负荷等）。也就是当各节点通信出现问题后，就会出现分区。 分区容忍性，即系统在出现分区后，仍应该能够容忍这种错误，继续运行，并提供服务。 三、CAP简易证明 CAP原理指出，分布式系统是无法同时满足以上三个特性。 例如，假设我们有一个简易分布式系统（由服务器节点$S_1$和$S_2$构成)，同时满足一致性、可用性和分区容忍性 假设有网络故障，因为我们的系统是分区容错的，它应该可以工作。在网络故障期间，客户端向服务器$S_1$发送写请求。$S_1$ 将接收请求并处理它。 如果我们的系统是一致的，$S_1$必须在向客户端确认之前更新$S_2$中的值，但由于网络故障，$S_1$ 无法更新 $S_2$。在这种情况下，对 $S_1$ 的请求将超时，这意味着我们的系统不可用。 如果我们的系统可用，$S_1$将响应客户端，而无需等待$S_2$中的更新。如果任何客户端向$S_2$发出相同信息的读取请求，它将收到较旧的值，而不是最近写入的结果。这意味着我们的系统在可用时无法保持一致。 四、 CAP的选择在分布式系统中，分区容忍性P是必须的。没有分布式系统可以避免通讯故障。所以我们必须保障系统在存在分区时仍正常提供服务。第二个选项就只能是一致性Consistency和可用性Availability。 CAP 定理经常被误解为必须始终在三个保证中选择两个。实际上，只有在网络分区或发生故障时，才需要在一致性和可用性之间进行选择。在没有网络分区或网络故障的情况下，可以同时满足可用性和一致性。 在存在分区的情况下，剩下两个选项一致性和可用性。 AP（Availability and Partition tolerance）：当可用性高于一致性时，系统将始终处理客户端请求并尝试返回最新可用版本的信息，即使由于网络分区而无法保证它是最新的。比如Spring Cloud中的Eureka。 CP(Consistency and Partition tolerance): 当一致性高于可用性时，如果系统出现分区，系统将对客户端的请求返回错误或超时。比如Zookeeper。 采用ACID保证 (RDBMS)设计的数据库系统通常选择一致性而不是可用性，而采用BASE保证设计的系统则选择可用性而不是一致性。 其实在实际工程中，可用性和一致性并不是完全对立的，我们往往关注的是如何在保持相对一致性的前提下，提高系统的可用性。至于是使用CP或者AP架构，则取决于业务对一致性的要求。 五、从CAP到BASE Epay 的架构师 Dan Pritchett 根据他自身在大规模分布式系统的实践经验，总结出了 BASE 理论。 BASE 理论是对 CAP 理论的延伸，核心思想是即使无法做到强一致性（Strong Consistency），但应用可以采用适合的方式达到最终一致性（Eventual Consitency）。这是基于实践工程的理论，它弥补了CAP 理论过于抽象的问题，也同时解决了 AP 系统的总体工程实践思想，是分布式系统的核心理论之一。 后续有机会再补充BASE理论, 笔者精力有限，接下来会开始学习Linux系统内容。 >- 已阅留爪 (ฅ´ω`ฅ)- 可能会有的《系列总结》 -","link":"/xi-tong-she-ji/systemdesign-08-cap/"},{"title":"简单系统质量 —— SLO（二）","text":"一、服务水平目标(SLO) SLO: Service Level Objective 1.1 基本概念定义 指服务可靠性的目标水平，指定了服务所提供功能的一种期望状态。 意义 由于 SLO 是做出以数据为依据的可靠性决策的关键 它们是SRE实践的核心。 服务提供者用它来指定系统的预期状态; 开发人员编写代码来实现; 客户依赖于 SLO 进行商业判断。 示例 每分钟慢查询数量 &lt; 10 99% 访问延迟 &lt; 100ms 99% 每分QPS &gt; 10k/s SLO 几个最佳实践 明确指定计算的时间窗口 使用一致的时间窗口（例如：5min滚动窗口、15min滚动窗口、1h滚动窗口、24h级滚动窗口） 需要有免责条款（例如：95%的慢查询要达到SLO、95%的访问延迟要达到SLO） 1.2 遵循原则 测量系统当前状态 设置预期(expectations)，而不是保证(guarantees) 初期的 SLO 不适合作为服务质量的强化工具 改进 SLO 设置更低的响应时间、更改的吞吐量等 保持一定的安全缓冲 内部用的 SLO 要高于对外宣称的 SLO 不要超额完成 定期的 downtime 来使 SLO 不超额完成 设置SLO时的目标依赖于系统的不同状态(conditions)，根据不同状态设置不同的SLO， 1.3 SLO 的收益是什么？ 对于客户而言 是可预期的服务质量，可以简化客户端的系统设计 对于服务提供者而言 可预期的服务质量 更好的取舍成本/收益 更好的风险控制(当资源受限的时候) 故障时更快的反应，采取正确措施 1.4 SLO 有哪些特性? SLO 是用基于SLI的 指定了服务所提供功能的一种期望状态； SLO 是一种工具，可帮助您确定要优先处理的工程工作； SLO 为服务的客户设置了目标可靠性级别。 1.5 如何保证能够达到目标呢？ 需要一个监控系统 监控/测量 SLIs 对比检测到的 SLIs 值是否达到目标 如果需要，修证目标或者修正系统以满足目标需要 实施目标的修改或者系统的修改 该监控系统需要重复的执行以上动作，以形成一个标准的反馈环路，不断的衡量和改进 SLO 以及服务本身。","link":"/sre/systemmonitor-02-slo/"},{"title":"简单系统质量 —— SLA（三）","text":"服务质量协议(SLA) SLI: Service Level Agreement 基本概念 定义 服务等级协议、服务水平协议，是服务提供商与客户之间定义的正式承诺。 特点 服务提供商与受服务用户之间具体达成了承诺的服务指标: 质量、可用性，责任。 描述 SLA = SLO + 后果 意义 便于提升实践项目的实施质量 便于降低实践项目的修改率与质疑率 加强了实践项目的协作关系","link":"/sre/systemmonitor-03-sla/"},{"title":"简单系统质量 —— SLI（一）","text":"一、服务质量指标(SLI) SLI: Service Level Indicator 1.1 基本概念定义 该服务的某项服务质量的一个具体量化指标。 特点 随着时间变化的度量值 意义 通过 SLI 测量出服务的质量指标，该值用于描述 SLO 示例 请求计数：5分钟内慢查询数量、每分钟慢请求数量。 响应延迟时间：慢查询的执行时间、慢请求的响应延迟 1.2 可测量指标分类性能 响应时间(latency) 吞吐量(throughput) 请求量(qps) 实效性(freshness) 可用性 运行时间(uptime) 故障时间/频率 高可用 质量 准确性(accuracy) 正确性(correctness) 完整性(completeness) 覆盖率(coverage) 相关性(relevance) 内部指标 队列长度(queue length) 内存占用(RAM usage) 因素 响应时间(time to response) 修复时间(time to fix) 修复率(fraction fixed) 常见问题 要测量的指标是什么？ 测量时的系统状态？ 如何汇总处理测量的指标？ 测量指标能否准确描述服务质量？ 测量指标的可靠度(trustworthy)？ 不同类型组建的潜在SLI：可用性、延迟、质量、时效性、正确率、覆盖率、持久性 举例说明： Outlook的downtime SLI 错误率(error rate)计算的是服务返回给用户的error总数 如果错误率大于X%，就算是服务down了，开始计算downtime 如果错误率持续超过Y分钟，这个downtime就会被计算在内 间断性的小于Y分钟的downtime是不被计算在内的。 1.3测量时的系统状态，在什么情况下测量会严重影响测量的结果 测量异常(badly-formed)请求，还是失败(fail)请求还是超时请求(timeout) 测量时的系统负载（是否最大负载） 测量的发起位置，服务器端还是客户端 测量的时间窗口（仅工作日、还是一周7天、是否包括计划内的维护时间段） 常见的处理测量的指标？ 计算的时间区间是什么：是一个滚动时间窗口，还是简单的按照月份计算 使用平均值还是百分位值，比如：某服务 X 的 ticket 处理响应时间 SLI 的 测量指标：统计所有成功解决请求，从用户创建 ticket到问题被解决的时间 怎么测量：用 ticket 自带的时间戳，统计所有用户创建的 ticket 什么情况下的测量：只包括工作时间，不包含法定假日 用于SLI的数据指标：以一周为滑动窗口，95%分位的解决时间 1.4 测量指标能否准确描述服务质量？ 性能：时效性、是否有偏差 准确性：精度、覆盖率、数据稳定性 完整性：数据丢失、无效数据、异常(outlier)数据 1.4 测量指标的可靠度 是否服务提供者和客户都认可 是否可被独立验证，比如三方机构 客户端还是服务器端测量，取样间隔 错误请求是如何计算的","link":"/sre/systemmonitor-01-sli/"},{"title":"Visual Studio ——  详解解决方案文件格式（.sln）","text":"一、前言 Foreword 在微软的工作过程中，免不了要跟Visual Studio打交道，就做了些学习记录。 其实在大部分时候，并不需要对Visual Studio的解决方案文件（*.sln*)要求足够的理解，因为宇宙最强IDE已经对该文件的自我修复能力已经拉满了。 出于了解，介绍下该文件的格式内容。可以参考官方文档 二、 概述 OverviewVisual Studio 的解决方案文件分成三个部分组成： 版本信息1234Microsoft Visual Studio Solution File, Format Version 12.00# Visual Studio Version 16VisualStudioVersion = 16.0.30111.22MinimumVisualStudioVersion = 10.0.40219.1 项目信息12ProjectEndProject 全局信息12GlobalEndGlobal 除了版本号之外，项目信息和全局信息有较多内容是关联的。 比如我们来看一个 sln 文件的例子，是一个最简单的只有一个项目的 sln 文件： 123456789101112131415161718192021222324Microsoft Visual Studio Solution File, Format Version 12.00# Visual Studio Version 16VisualStudioVersion = 16.0.30111.22MinimumVisualStudioVersion = 10.0.40219.1Project(&quot;{9A19103F-16F7-4668-BE54-9A1E7A4F7556}&quot;) = &quot;Solution.Demo&quot;, &quot;Solution.Demo\\Solution.Demo.csproj&quot;, &quot;{DC0B1D44-5DF4-4590-BBFE-072183677A78}&quot;EndProjectGlobal GlobalSection(SolutionConfigurationPlatforms) = preSolution Debug|Any CPU = Debug|Any CPU Release|Any CPU = Release|Any CPU EndGlobalSection GlobalSection(ProjectConfigurationPlatforms) = postSolution {DC0B1D44-5DF4-4590-BBFE-072183677A78}.Debug|Any CPU.ActiveCfg = Debug|Any CPU {DC0B1D44-5DF4-4590-BBFE-072183677A78}.Debug|Any CPU.Build.0 = Debug|Any CPU {DC0B1D44-5DF4-4590-BBFE-072183677A78}.Release|Any CPU.ActiveCfg = Release|Any CPU {DC0B1D44-5DF4-4590-BBFE-072183677A78}.Release|Any CPU.Build.0 = Release|Any CPU EndGlobalSection GlobalSection(SolutionProperties) = preSolution HideSolutionNode = FALSE EndGlobalSection GlobalSection(ExtensibilityGlobals) = postSolution SolutionGuid = {F05207D3-0956-46BE-AEEA-51B9F2531A53} EndGlobalSectionEndGlobal 下面我们来一一说明。 三、各部分详讲3.1 版本信息1234Microsoft Visual Studio Solution File, Format Version 12.00# Visual Studio Version 16VisualStudioVersion = 16.0.30111.22MinimumVisualStudioVersion = 10.0.40219.1 记录文件的格式版本是 12.0。使用 Visual Studio 2019 编辑/创建。 这里有一个小技巧，这里的 VisualStudioVersion 版本号设置为 15.0 会使得打开 sln 文件的时候默认使用 Visual Studio 2017，而设置为 16.0 会使得打开 sln 文件的时候默认使用 Visual Studio 2019。 3.1 项目信息Project Project和是一个项目的开始和结束位置的关键字，是配对出现的。 123ProjectProject(&quot;{9A19103F-16F7-4668-BE54-9A1E7A4F7556}&quot;) = &quot;Solution.Demo&quot;, &quot;Solution.Demo\\Solution.Demo.csproj&quot;, &quot;{DC0B1D44-5DF4-4590-BBFE-072183677A78}&quot;EndProject 其格式为： 12Project(&quot;{项目类型}&quot;) = &quot;项目名称&quot;, &quot;项目路径&quot;, &quot;项目 Id&quot;EndProject 项目类型ID: .Net/C#项目类型分为SDK风格, 传统风格和传统解决方案等等。更多类型可以参考visual-studio-project-type-guids StackOverflow 项目名称&amp;项目路径： 项目名称，也就是文件夹名字。项目路径就是csproj的路径。 项目ID: 在解决方案创建项目的过程中生成的一个新的GUID，每个项目都不一样。对于 SDK 风格的 C# 项目文件，csproj 中可以指定项目依赖，而如果没有直接的项目依赖，而只是解决方案编译级别的依赖，那么也可以靠 sln 文件中的项目 Id 来指定项目的依赖关系。另外，也通过项目 Id 来对项目做一些编译上的解决方案级别的配置。 ProjectSection Project 和 EndProject 的内部还可以放 ProjectSection。 比如对于解决方案文件夹，可以包含解决方案文件： 12345678Project(&quot;{2150E333-8FDC-42A3-9474-1A3956D46DE8}&quot;) = &quot;Solution Items&quot;, &quot;Solution Items&quot;, &quot;{B002382D-4C9E-4F08-85E5-F12E2C061F5A}&quot; ProjectSection(SolutionItems) = preProject .gitattributes = .gitattributes .gitignore = .gitignore README.md = README.md build\\Version.props = build\\Version.props EndProjectSectionEndProject 这个解决方案文件夹中包含了四个文件，其路径分别记录在了 ProjectSection 节点里面。 ProjectSection 还可以记录项目依赖关系（非项目之间的真实依赖，而是解决方案级别的编译依赖）： 1234567Project(&quot;{9A19103F-16F7-4668-BE54-9A1E7A4F7556}&quot;) = &quot;Solution.Demo&quot;, &quot;Solution.Demo\\Solution.Demo.csproj&quot;, &quot;{DC0B1D44-5DF4-4590-BBFE-072183677A78}&quot; ProjectSection(ProjectDependencies) = postProject {98FF9756-B95A-4FDB-9858-5106F486FBF3} = {98FF9756-B95A-4FDB-9858-5106F486FBF3} EndProjectSectionEndProjectProject(&quot;{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}&quot;) = &quot;Solution.Demo2&quot;, &quot;Solution.Demo2\\Solution.Demo2.csproj&quot;, &quot;{98FF9756-B95A-4FDB-9858-5106F486FBF3}&quot;EndProject 在这一段节点里面，我们的 Solution.Demo 项目依赖于另外一个 Solution.Demo2 项目。依赖是以 项目 Id = 项目 Id 的方式写出来的；如果有多个依赖，那么就写多行。不用吐槽为什么一样还要写两遍，因为这是一个固定的格式，后面我们会介绍一些全局配置里面会有两个不一样的。 关于设置项目依赖关系的方法，除了 sln 文件里面的设置之外，还有通过设置项目依赖属性的方式，这里不增加描述。 3.3 全局信息一个全局信息的例子如下： 12345678910111213141516171819202122Global GlobalSection(SolutionConfigurationPlatforms) = preSolution Debug|Any CPU = Debug|Any CPU Release|Any CPU = Release|Any CPU EndGlobalSection GlobalSection(ProjectConfigurationPlatforms) = postSolution {9A19103F-16F7-4668-BE54-9A1E7A4F7556}.Debug|Any CPU.ActiveCfg = Debug|Any CPU {9A19103F-16F7-4668-BE54-9A1E7A4F7556}.Debug|Any CPU.Build.0 = Debug|Any CPU {9A19103F-16F7-4668-BE54-9A1E7A4F7556}.Release|Any CPU.ActiveCfg = Release|Any CPU {9A19103F-16F7-4668-BE54-9A1E7A4F7556}.Release|Any CPU.Build.0 = Release|Any CPU {98FF9756-B95A-4FDB-9858-5106F486FBF3}.Debug|Any CPU.ActiveCfg = Debug|Any CPU {98FF9756-B95A-4FDB-9858-5106F486FBF3}.Debug|Any CPU.Build.0 = Debug|Any CPU {98FF9756-B95A-4FDB-9858-5106F486FBF3}.Release|Any CPU.ActiveCfg = Release|Any CPU {98FF9756-B95A-4FDB-9858-5106F486FBF3}.Release|Any CPU.Build.0 = Release|Any CPU EndGlobalSection GlobalSection(SolutionProperties) = preSolution HideSolutionNode = FALSE EndGlobalSection GlobalSection(ExtensibilityGlobals) = postSolution SolutionGuid = {F2F1AD1B-207B-4731-ABEB-92882F89B155} EndGlobalSectionEndGlobal 在这个全局信息的例子中，为解决方案指定了两个配置（Configuration），Debug 和 Release，平台都是 Any CPU。同时也为每个项目指定了单独的配置种类，可供选择，每一行都是 项目的配置 = 解决方案的配置 表示此项目的此种配置在解决方案的某个全局配置之下。 如果我们将这两个项目放到文件夹中，那么我们可以额外看到一个新的全局配置 NestedProjects 字面意思是说 {DC0B1D44-5DF4-4590-BBFE-072183677A78} 和 {98FF9756-B95A-4FDB-9858-5106F486FBF3} 两个项目在 {20B61509-640C-492B-8B33-FB472CCF1391} 项目中嵌套，实际意义代表 Solution.Demo 和 Solution.Demo2 两个项目在 Folder 文件夹下。 1234GlobalSection(NestedProjects) = preSolution {DC0B1D44-5DF4-4590-BBFE-072183677A78} = {20B61509-640C-492B-8B33-FB472CCF1391} {98FF9756-B95A-4FDB-9858-5106F486FBF3} = {20B61509-640C-492B-8B33-FB472CCF1391}EndGlobalSection","link":"/visual-studio/visualstudio-solutionfile-sln/"}],"tags":[{"name":"软知识","slug":"软知识","link":"/tags/%E8%BD%AF%E7%9F%A5%E8%AF%86/"},{"name":"个人技能","slug":"个人技能","link":"/tags/%E4%B8%AA%E4%BA%BA%E6%8A%80%E8%83%BD/"},{"name":"职业发展","slug":"职业发展","link":"/tags/%E8%81%8C%E4%B8%9A%E5%8F%91%E5%B1%95/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"Git","slug":"Git","link":"/tags/Git/"},{"name":"VCS","slug":"VCS","link":"/tags/VCS/"},{"name":"面试","slug":"面试","link":"/tags/%E9%9D%A2%E8%AF%95/"},{"name":"操作系统","slug":"操作系统","link":"/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"系统设计","slug":"系统设计","link":"/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"name":"缓存","slug":"缓存","link":"/tags/%E7%BC%93%E5%AD%98/"},{"name":"分布式系统","slug":"分布式系统","link":"/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"},{"name":"NPM","slug":"NPM","link":"/tags/NPM/"},{"name":"知识地图","slug":"知识地图","link":"/tags/%E7%9F%A5%E8%AF%86%E5%9C%B0%E5%9B%BE/"},{"name":"JavaScript","slug":"JavaScript","link":"/tags/JavaScript/"},{"name":"负载均衡","slug":"负载均衡","link":"/tags/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"name":"索引","slug":"索引","link":"/tags/%E7%B4%A2%E5%BC%95/"},{"name":"分布式数据库","slug":"分布式数据库","link":"/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"代理","slug":"代理","link":"/tags/%E4%BB%A3%E7%90%86/"},{"name":"哈希","slug":"哈希","link":"/tags/%E5%93%88%E5%B8%8C/"},{"name":"CAP","slug":"CAP","link":"/tags/CAP/"},{"name":"SRE","slug":"SRE","link":"/tags/SRE/"},{"name":"SLO","slug":"SLO","link":"/tags/SLO/"},{"name":"SLA","slug":"SLA","link":"/tags/SLA/"},{"name":"SLI","slug":"SLI","link":"/tags/SLI/"},{"name":"Visual Studio","slug":"Visual-Studio","link":"/tags/Visual-Studio/"}],"categories":[{"name":"胡言乱语","slug":"胡言乱语","link":"/categories/%E8%83%A1%E8%A8%80%E4%B9%B1%E8%AF%AD/"},{"name":"Hexo","slug":"Hexo","link":"/categories/Hexo/"},{"name":"Git","slug":"Git","link":"/categories/Git/"},{"name":"程序员面试攻略","slug":"程序员面试攻略","link":"/categories/%E7%A8%8B%E5%BA%8F%E5%91%98%E9%9D%A2%E8%AF%95%E6%94%BB%E7%95%A5/"},{"name":"Linux操作系统","slug":"Linux操作系统","link":"/categories/Linux%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"系统设计","slug":"系统设计","link":"/categories/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"name":"瞎折腾系列","slug":"瞎折腾系列","link":"/categories/%E7%9E%8E%E6%8A%98%E8%85%BE%E7%B3%BB%E5%88%97/"},{"name":"SRE","slug":"SRE","link":"/categories/SRE/"},{"name":"Visual Studio","slug":"Visual-Studio","link":"/categories/Visual-Studio/"}],"pages":[{"title":"categories","text":"","link":"/categories/index.html"},{"title":"404","text":"","link":"/404/index.html"},{"title":"radar","text":"","link":"/radar/index.html"},{"title":"about","text":"","link":"/about/index.html"},{"title":"comments","text":"","link":"/comments/index.html"}]}